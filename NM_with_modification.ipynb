{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "3f9c26be-121f-4f7a-a978-2a8fbca3d0a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T22:14:46.288326Z",
     "iopub.status.busy": "2023-06-05T22:14:46.288326Z",
     "iopub.status.idle": "2023-06-05T22:14:46.299836Z",
     "shell.execute_reply": "2023-06-05T22:14:46.299336Z",
     "shell.execute_reply.started": "2023-06-05T22:14:46.288326Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numdifftools.core import Gradient, Hessian\n",
    "import matplotlib.pyplot as plt\n",
    "import decimal\n",
    "from decimal import Decimal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfde008-225c-4196-830c-a7413f3c2087",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3>Problem 1:</h3>\n",
    "$$f(x_1, x_2)=100(x_2-x_1^2)^2+(1-x_1)^2$$\n",
    "$$f'(x_1, x_2)=\\begin{pmatrix}\n",
    "-400x_1(x_2-x_1^2)-2(1-x_1)\\\\ \n",
    "200(x_2-x_1^2)\\\\ \n",
    "\\end{pmatrix}$$\n",
    "$$f''(x_1, x_2)=\\begin{pmatrix}\n",
    "1200x_1^2-400x_2+2 & -400x_1\\\\ \n",
    "-400x_1 & 200\\\\ \n",
    "\\end{pmatrix}$$\n",
    "on the starting points $x_0$:\n",
    "$$(1.2, 1.2), (-1.2, 1), (0.2, 0.8)$$\n",
    "with the minimum at $x^*=(1,1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "cd1520c4-bdbb-4ecd-a12a-b1cfb23cabb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T22:16:33.729185Z",
     "iopub.status.busy": "2023-06-05T22:16:33.728684Z",
     "iopub.status.idle": "2023-06-05T22:16:33.738193Z",
     "shell.execute_reply": "2023-06-05T22:16:33.738193Z",
     "shell.execute_reply.started": "2023-06-05T22:16:33.729185Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fct_1(x: np.array) -> int:\n",
    "    return 100*(x[1]-x[0]**2)**2 + (1-x[0])**2\n",
    "\n",
    "def grad_fct_1(x: np.array) -> np.array:\n",
    "    return np.array([-400*x[0]*(x[1]-x[0]**2)-2*(1-x[0]),\n",
    "                    200*(x[1]-x[0]**2)], dtype=np.float64)\n",
    "\n",
    "def hessian_fct_1(x: np.array) -> np.array:\n",
    "    return np.array([[1200*x[0]**2-400*x[1]+2, -400*x[0]], \n",
    "                     [-400*x[0], 200]], dtype=np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2591b7-a476-4348-82da-9d76ba97dfd7",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3>Problem 2:</h3>\n",
    "$$f(x_1, x_2)=150(x_1 x_2)^2+(0.5x_1 + 2x_2 - 2)^2$$\n",
    "$$f'(x_1, x_2)=\\begin{pmatrix}\n",
    "300x_2^2 x_1 + 0.5 x_1 + 2x_2 - 2\\\\ \n",
    "300x_1^2 x_2 + 2x_1 + 8x_2 - 8\\\\ \n",
    "\\end{pmatrix}$$\n",
    "$$f''(x_1, x_2)=\\begin{pmatrix}\n",
    "300x_2^2 +0.5 & 600x_1 x_2+2\\\\ \n",
    "600x_1 x_2+2 & 300x_1^2 +8\\\\ \n",
    "\\end{pmatrix}$$\n",
    "\n",
    "on the starting points $x_0$:\n",
    "$$(-0.2, 1.2), (3.8, 0.1), (1.9, 0.6)$$<br>\n",
    "with the minimums at $x^*=(0,1)$ and $x^*=(4,0)$ and a saddle point at $(0.43685, 0.10921)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "id": "6069e364-74ac-4c06-81b9-5745c99d45ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T22:34:12.559084Z",
     "iopub.status.busy": "2023-06-05T22:34:12.558584Z",
     "iopub.status.idle": "2023-06-05T22:34:12.568092Z",
     "shell.execute_reply": "2023-06-05T22:34:12.568092Z",
     "shell.execute_reply.started": "2023-06-05T22:34:12.559084Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fct_2(x: np.array) -> int:\n",
    "    return 150*(x[0] * x[1])**2 + (0.5 * x[0] + 2*x[1] - 2)**2\n",
    "\n",
    "def fct_2_dec(x: np.array) -> int:\n",
    "    return 150*(Decimal(x[0]) * Decimal(x[1]))**2 + (Decimal(0.5) * Decimal(x[0]) + 2*Decimal(x[1]) - 2)**2\n",
    "\n",
    "def grad_fct_2(x: np.array) -> np.array:\n",
    "    return np.array([300*x[0]*x[1]**2 + 0.5*x[0]+2*x[1]-2,\n",
    "                     300*(x[0]**2)*x[1] + 2*x[0]+8*x[1]-8], dtype=np.float64)\n",
    "\n",
    "def hessian_fct_2(x: np.array) -> np.array:\n",
    "    return np.array([[300*x[1]**2 + 0.5, 600*x[0]*x[1] + 2], \n",
    "                     [600*x[0]*x[1] + 2, 300*x[0]**2 + 8]], dtype=np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58525c1-04b2-42c6-92ac-48fb7eebaa00",
   "metadata": {},
   "source": [
    "<h2>1. Implementation of NM with hessian modification</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "id": "0a20f278-f22f-46fa-9e64-161c9de62478",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T22:35:04.623624Z",
     "iopub.status.busy": "2023-06-05T22:35:04.623124Z",
     "iopub.status.idle": "2023-06-05T22:35:04.636135Z",
     "shell.execute_reply": "2023-06-05T22:35:04.635635Z",
     "shell.execute_reply.started": "2023-06-05T22:35:04.623624Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Backtrack(f, x, gradient, pk, alpha_zero=1, rho=0.5, c=0.5):\n",
    "    alpha = alpha_zero\n",
    "\n",
    "    while not f(x + alpha * pk) <= float(f(x)) + c * alpha * np.dot(gradient.T, pk):\n",
    "        alpha *= rho\n",
    "        \n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "id": "7acef10c-7e0a-4bdd-9634-7d2fd2ec5809",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T22:35:11.312969Z",
     "iopub.status.busy": "2023-06-05T22:35:11.312468Z",
     "iopub.status.idle": "2023-06-05T22:35:11.324979Z",
     "shell.execute_reply": "2023-06-05T22:35:11.324478Z",
     "shell.execute_reply.started": "2023-06-05T22:35:11.312969Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def is_pos_def_1(A):\n",
    "    if np.array_equal(A, A.T):\n",
    "        try:\n",
    "            np.linalg.cholesky(A)\n",
    "            return True\n",
    "        except np.linalg.LinAlgError:\n",
    "            return False\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "1f8722cb-95e6-486b-b746-065a9c96edec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T22:14:46.988428Z",
     "iopub.status.busy": "2023-06-05T22:14:46.988428Z",
     "iopub.status.idle": "2023-06-05T22:14:46.997936Z",
     "shell.execute_reply": "2023-06-05T22:14:46.997435Z",
     "shell.execute_reply.started": "2023-06-05T22:14:46.988428Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def is_pos_def(A):\n",
    "    try:\n",
    "        np.linalg.cholesky(A)\n",
    "        return True\n",
    "    except np.linalg.LinAlgError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "9bc418b4-4db1-4ca3-b982-d5e4cb5f9528",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T22:14:47.033466Z",
     "iopub.status.busy": "2023-06-05T22:14:47.032965Z",
     "iopub.status.idle": "2023-06-05T22:14:47.044475Z",
     "shell.execute_reply": "2023-06-05T22:14:47.043975Z",
     "shell.execute_reply.started": "2023-06-05T22:14:47.033466Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cholesky(a):\n",
    "    iters = 100000\n",
    "    i = 0\n",
    "    beta = 1\n",
    "    m = np.amin(np.diag(a))\n",
    "    if m > 0:\n",
    "        t = 0\n",
    "    else:\n",
    "        t = beta - m\n",
    "    \n",
    "    while i < iters:\n",
    "        #print(a+np.dot(t,np.eye(a.shape[0])))\n",
    "        try:\n",
    "            l = np.linalg.cholesky(a+np.dot(t,np.eye(a.shape[0])))\n",
    "            return l\n",
    "        except np.linalg.LinAlgError:\n",
    "            if 2*t > beta:\n",
    "                t = 2*t\n",
    "            else:\n",
    "                t = beta\n",
    "            i += 1\n",
    "    return 'fail'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "bc9037ef-44b6-492b-b10a-535e31adc5dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T22:29:15.853671Z",
     "iopub.status.busy": "2023-06-05T22:29:15.853171Z",
     "iopub.status.idle": "2023-06-05T22:29:15.870687Z",
     "shell.execute_reply": "2023-06-05T22:29:15.870186Z",
     "shell.execute_reply.started": "2023-06-05T22:29:15.853671Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def newton_method(f, grad, hess, x0, max_iter=10000, tol=1e-6, c=0.05, rho=0.5, estimate=False):\n",
    "    \n",
    "    x = x0\n",
    "    num_iter = 0\n",
    "    e_g = Decimal(0.0000000000001)\n",
    "    e_h = Decimal(0.00000001)\n",
    "    \n",
    "    while num_iter < max_iter:\n",
    "        if estimate:\n",
    "            x_dec = np.array([Decimal(val) for val in x])\n",
    "            gradient = grad(f,x_dec,e_g)\n",
    "            hessian = hess(f,x_dec,e_h,e_g)\n",
    "            #print(gradient)\n",
    "        else:  \n",
    "            gradient = grad(x)\n",
    "            hessian = hess(x) \n",
    "            #print(x,gradient)\n",
    "        \n",
    "        grad_norm = np.linalg.norm(gradient)\n",
    "        if grad_norm < tol:\n",
    "            break\n",
    "                \n",
    "        a=np.atleast_2d(hessian)\n",
    "        #print(a)\n",
    "        if not is_pos_def(a): #check if hessian is pos. definite, else make it pos. definite\n",
    "            a = cholesky(a)\n",
    "            #print('a')\n",
    "        b=np.atleast_1d(gradient)\n",
    "        search_direction = np.linalg.solve(a, -b)#[0]\n",
    "        #print(search_direction)\n",
    "        \n",
    "        alpha = Backtrack(f=f, x=x, gradient=gradient, pk=search_direction, alpha_zero=1, rho=rho, c=c)\n",
    "        #print(alpha)\n",
    "        \n",
    "        #print(x,gradient,hessian,alpha)\n",
    "        x = x + alpha * search_direction\n",
    "        num_iter += 1\n",
    "        \n",
    "    x_star = x\n",
    "    f_star = f(x_star)\n",
    "    return x_star, round(f_star,15), num_iter, grad_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "fd38b08c-3565-420a-8853-e3307c1f2f3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T22:29:16.024818Z",
     "iopub.status.busy": "2023-06-05T22:29:16.024318Z",
     "iopub.status.idle": "2023-06-05T22:29:16.041333Z",
     "shell.execute_reply": "2023-06-05T22:29:16.040832Z",
     "shell.execute_reply.started": "2023-06-05T22:29:16.024818Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def newton_method_1(f, grad, hess, x0, max_iter=10000, tol=1e-6, c=0.05, rho=0.5):\n",
    "\n",
    "    x = x0                     \n",
    "    num_iter = 0\n",
    "    while num_iter < max_iter:\n",
    "        gradient = grad(x)\n",
    "        hessian = hess(x)   \n",
    "        \n",
    "        grad_norm = np.linalg.norm(gradient)\n",
    "        if grad_norm < tol:\n",
    "            break\n",
    "                \n",
    "        a=np.atleast_2d(hessian)\n",
    "        i=0\n",
    "        while not is_pos_def(a): #check if hessian is pos. definite, else make it pos. definite\n",
    "            a += 1\n",
    "            if i < 10:\n",
    "                #print(a)\n",
    "                i += 1\n",
    "            #print('modify')\n",
    "        b=np.atleast_1d(gradient)\n",
    "        search_direction = np.linalg.solve(a, -b)#[0]\n",
    "        #print(search_direction)\n",
    "         \n",
    "        alpha = Backtrack(f=f, x=x, gradient=gradient, pk=search_direction, alpha_zero=1, rho=rho, c=c)\n",
    "        #print(alpha)\n",
    "        \n",
    "        x = x + alpha * search_direction\n",
    "        num_iter += 1\n",
    "        \n",
    "    x_star = x\n",
    "    f_star = f(x_star)\n",
    "    return x_star, round(f_star,15), num_iter, grad_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc9a21e-470e-48dc-97aa-feed3e4bdcba",
   "metadata": {},
   "source": [
    "<h2>3. Gradient and hessian approximation</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "80e96952-50d9-4a78-9fb1-d78459004a40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T22:29:16.336612Z",
     "iopub.status.busy": "2023-06-05T22:29:16.336111Z",
     "iopub.status.idle": "2023-06-05T22:29:16.351625Z",
     "shell.execute_reply": "2023-06-05T22:29:16.351125Z",
     "shell.execute_reply.started": "2023-06-05T22:29:16.336612Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use to get gradient as np.array\n",
    "def grad_estimate_np(f, x: np.array, eps: decimal.Decimal):\n",
    "    grad=np.full(len(x), Decimal(0))\n",
    "    for i in range(len(x)):\n",
    "        unit_vector = np.full(len(x), Decimal(0))\n",
    "        unit_vector[i] = Decimal(1)\n",
    "        grad[i] = round(float((f(x + (eps * unit_vector)) - f(x)) / eps), 15)\n",
    "    return np.array(grad, dtype=float)\n",
    "\n",
    "# use for further calculation of hessian estimate\n",
    "def grad_estimate(f, x: np.array, eps: decimal.Decimal):\n",
    "    grad=np.full(len(x), Decimal(0))\n",
    "    for i in range(len(x)):\n",
    "        unit_vector = np.full(len(x), Decimal(0))\n",
    "        unit_vector[i] = Decimal(1)\n",
    "        grad[i] = (f(x + (eps * unit_vector)) - f(x)) / eps\n",
    "    return np.array(grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "7150356c-b53e-487a-99d5-a867e3a42a87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T22:29:16.506755Z",
     "iopub.status.busy": "2023-06-05T22:29:16.506755Z",
     "iopub.status.idle": "2023-06-05T22:29:16.522268Z",
     "shell.execute_reply": "2023-06-05T22:29:16.521768Z",
     "shell.execute_reply.started": "2023-06-05T22:29:16.506755Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def hessian_estimate(f, x: np.array, eps_hess: decimal.Decimal, eps_grad):\n",
    "    hessian = np.full((len(x), len(x)), Decimal(0))\n",
    "    for i in range(len(x)):\n",
    "        unit_vector = np.full(len(x), Decimal(0))\n",
    "        unit_vector[i] = Decimal(1)\n",
    "        hessian[:, i] = np.array([round(float(g),15) for g in (np.divide(grad_estimate(f=f, x=(x + (eps_hess * unit_vector)), eps=eps_grad) - grad_estimate(f=f, x=x, eps=eps_grad), eps_hess))])\n",
    "    return np.array(hessian, dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b29a8ee-fff5-4aec-939c-275731e94517",
   "metadata": {},
   "source": [
    "<h2>4. Problems to test NM with hessian modification using exact derivatives</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd3f50b-ec01-4502-9ce9-bb7498d19d8a",
   "metadata": {},
   "source": [
    "<h3>Problem 1.1:</h3>\n",
    "$$f(x_1, x_2)=100(x_2-x_1^2)^2+(1-x_1)^2$$\n",
    "$$f'(x_1, x_2)=\\begin{pmatrix}\n",
    "-400x_1(x_2-x_1^2)-2(1-x_1)\\\\ \n",
    "200(x_2-x_1^2)\\\\ \n",
    "\\end{pmatrix}$$\n",
    "$$f''(x_1, x_2)=\\begin{pmatrix}\n",
    "1200x_1^2-400x_2+2 & -400x_1\\\\ \n",
    "-400x_1 & 200\\\\ \n",
    "\\end{pmatrix}$$\n",
    "on the starting points $x_0$:\n",
    "$$(1.2, 1.2)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b88e37-4cb7-4ccf-9d1d-90becc93c1ae",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h4>using exact gradient and hessian:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "76cba7fe-a650-4b73-ba2e-9e0f2c1ded71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T22:29:17.411718Z",
     "iopub.status.busy": "2023-06-05T22:29:17.411218Z",
     "iopub.status.idle": "2023-06-05T22:29:17.421726Z",
     "shell.execute_reply": "2023-06-05T22:29:17.421226Z",
     "shell.execute_reply.started": "2023-06-05T22:29:17.411718Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum 0.0  at x = [1. 1.] after 8    iterations with remaining gradient norm 1.4360392201267428e-11\n"
     ]
    }
   ],
   "source": [
    "x_0= np.array([1.2, 1.2])\n",
    "x_star, fval, it, grad_norm = newton_method(fct_1, grad_fct_1, hessian_fct_1, x_0, max_iter=100)\n",
    "print(f'minimum {fval:<4} at x = {x_star} after {it:<4} iterations with remaining gradient norm {grad_norm}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb349d75-ea46-4faa-93e4-2a4872c6db6f",
   "metadata": {},
   "source": [
    "<h4>using approximated gradient and hessian:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "c367c347-9556-4349-9ac2-0790bad6af93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T22:29:18.172715Z",
     "iopub.status.busy": "2023-06-05T22:29:18.172715Z",
     "iopub.status.idle": "2023-06-05T22:29:18.179720Z",
     "shell.execute_reply": "2023-06-05T22:29:18.179720Z",
     "shell.execute_reply.started": "2023-06-05T22:29:18.172715Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum 0.0  at x = [1. 1.] after 8    iterations with remaining gradient norm 1.6428426735387657e-11\n"
     ]
    }
   ],
   "source": [
    "x_star, fval, it, grad_norm = newton_method(fct_1, grad_estimate_np, hessian_estimate, x_0, max_iter=100, estimate=True)\n",
    "print(f'minimum {fval:<4} at x = {x_star} after {it:<4} iterations with remaining gradient norm {grad_norm}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49463131-4040-4725-87c5-0a601379411c",
   "metadata": {},
   "source": [
    "<h3>Problem 1.2:</h3>\n",
    "$$f(x_1, x_2)=100(x_2-x_1^2)^2+(1-x_1)^2$$\n",
    "$$f'(x_1, x_2)=\\begin{pmatrix}\n",
    "-400x_1(x_2-x_1^2)-2(1-x_1)\\\\ \n",
    "200(x_2-x_1^2)\\\\ \n",
    "\\end{pmatrix}$$\n",
    "$$f''(x_1, x_2)=\\begin{pmatrix}\n",
    "1200x_1^2-400x_2+2 & -400x_1\\\\ \n",
    "-400x_1 & 200\\\\ \n",
    "\\end{pmatrix}$$\n",
    "on the starting points $x_0$:\n",
    "$$(-1.2, 1)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2f2922-5c3c-451d-889f-7e62ca508e8e",
   "metadata": {},
   "source": [
    "<h4>using exact gradient and hessian:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "eeb83ba6-3e3b-4734-8542-e6e494b4b874",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T22:29:20.702114Z",
     "iopub.status.busy": "2023-06-05T22:29:20.701613Z",
     "iopub.status.idle": "2023-06-05T22:29:20.717628Z",
     "shell.execute_reply": "2023-06-05T22:29:20.717127Z",
     "shell.execute_reply.started": "2023-06-05T22:29:20.702114Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum 0.0  at x = [1. 1.] after 21   iterations with remaining gradient norm 1.2166683130616293e-10\n"
     ]
    }
   ],
   "source": [
    "x_0= np.array([-1.2, 1])\n",
    "x_star, fval, it, grad_norm = newton_method(fct_1, grad_fct_1, hessian_fct_1, x_0, max_iter=100)\n",
    "print(f'minimum {fval:<4} at x = {x_star} after {it:<4} iterations with remaining gradient norm {grad_norm}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763e2b1e-95e1-4083-8cf5-60df08bf2f71",
   "metadata": {},
   "source": [
    "<h4>using approximated gradient and hessian:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "de336cf6-bc27-45d1-88ca-9e8d416de8e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T22:29:21.161890Z",
     "iopub.status.busy": "2023-06-05T22:29:21.161389Z",
     "iopub.status.idle": "2023-06-05T22:29:21.182406Z",
     "shell.execute_reply": "2023-06-05T22:29:21.181906Z",
     "shell.execute_reply.started": "2023-06-05T22:29:21.161890Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum 0.0  at x = [1. 1.] after 21   iterations with remaining gradient norm 1.204456775895258e-10\n"
     ]
    }
   ],
   "source": [
    "x_star, fval, it, grad_norm = newton_method(fct_1, grad_estimate_np, hessian_estimate, x_0, max_iter=100, estimate=True)\n",
    "print(f'minimum {fval:<4} at x = {x_star} after {it:<4} iterations with remaining gradient norm {grad_norm}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a6bf30-2a06-4cde-b407-823f4fd571eb",
   "metadata": {},
   "source": [
    "<h3>Problem 1.3:</h3>\n",
    "$$f(x_1, x_2)=100(x_2-x_1^2)^2+(1-x_1)^2$$\n",
    "$$f'(x_1, x_2)=\\begin{pmatrix}\n",
    "-400x_1(x_2-x_1^2)-2(1-x_1)\\\\ \n",
    "200(x_2-x_1^2)\\\\ \n",
    "\\end{pmatrix}$$\n",
    "$$f''(x_1, x_2)=\\begin{pmatrix}\n",
    "1200x_1^2-400x_2+2 & -400x_1\\\\ \n",
    "-400x_1 & 200\\\\ \n",
    "\\end{pmatrix}$$\n",
    "on the starting points $x_0$:\n",
    "$$(0.2, 0.8)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cb4481-70fa-4a7d-9536-120585e5a088",
   "metadata": {},
   "source": [
    "<h4>using exact gradient and hessian:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "id": "03f5acfe-1566-410b-9458-5ac6003a1874",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T22:29:22.335627Z",
     "iopub.status.busy": "2023-06-05T22:29:22.335127Z",
     "iopub.status.idle": "2023-06-05T22:29:22.344134Z",
     "shell.execute_reply": "2023-06-05T22:29:22.344134Z",
     "shell.execute_reply.started": "2023-06-05T22:29:22.335627Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum 0.0  at x = [1. 1.] after 10   iterations with remaining gradient norm 5.699507176150195e-08\n"
     ]
    }
   ],
   "source": [
    "x_0= np.array([0.2, 0.8])\n",
    "x_star, fval, it, grad_norm = newton_method(fct_1, grad_fct_1, hessian_fct_1, x_0, max_iter=100)\n",
    "print(f'minimum {fval:<4} at x = {x_star} after {it:<4} iterations with remaining gradient norm {grad_norm}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce9066f-19e2-4197-8bae-c60178cff94a",
   "metadata": {},
   "source": [
    "<h4>using approximated gradient and hessian:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "id": "1b8fb662-3de3-4af5-962f-c4e321a65daf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T22:29:22.894782Z",
     "iopub.status.busy": "2023-06-05T22:29:22.894782Z",
     "iopub.status.idle": "2023-06-05T22:29:22.901787Z",
     "shell.execute_reply": "2023-06-05T22:29:22.901787Z",
     "shell.execute_reply.started": "2023-06-05T22:29:22.894782Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum 0.0  at x = [1. 1.] after 10   iterations with remaining gradient norm 5.69051174865548e-08\n"
     ]
    }
   ],
   "source": [
    "x_star, fval, it, grad_norm = newton_method(fct_1, grad_estimate_np, hessian_estimate, x_0, max_iter=100, estimate=True)\n",
    "print(f'minimum {fval:<4} at x = {x_star} after {it:<4} iterations with remaining gradient norm {grad_norm}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7964e6-d0c4-4663-8c38-1f9ab980727a",
   "metadata": {},
   "source": [
    "<h3>Problem 2.1:</h3>\n",
    "$$f(x_1, x_2)=150(x_1 x_2)^2+(0.5x_1 + 2x_2 - 2)^2$$\n",
    "$$f'(x_1, x_2)=\\begin{pmatrix}\n",
    "300x_2^2 x_1 + 0.5 x_1 + 2x_2 - 2\\\\ \n",
    "300x_1^2 x_2 + 2x_1 + 8x_2 - 8\\\\ \n",
    "\\end{pmatrix}$$\n",
    "$$f''(x_1, x_2)=\\begin{pmatrix}\n",
    "300x_2^2 +0.5 & 600x_1 x_2+2\\\\ \n",
    "600x_1 x_2+2 & 300x_1^2 +8\\\\ \n",
    "\\end{pmatrix}$$\n",
    "\n",
    "on the starting points $x_0$:\n",
    "$$(-0.2, 1.2)$$\n",
    "is close to the soltion $x^*=(0,1)$:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797d7d1d-fd44-4cc6-a2aa-d13c528d50be",
   "metadata": {},
   "source": [
    "<h4>using exact gradient and hessian:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "09bfdc15-5dd3-4b87-a097-121b62943ba9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T22:29:24.330154Z",
     "iopub.status.busy": "2023-06-05T22:29:24.329654Z",
     "iopub.status.idle": "2023-06-05T22:29:24.342665Z",
     "shell.execute_reply": "2023-06-05T22:29:24.342164Z",
     "shell.execute_reply.started": "2023-06-05T22:29:24.330154Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum 0.0  at x = [-4.71275675e-14  1.00000000e+00] after 6    iterations with remaining gradient norm 1.4028846968253339e-11\n"
     ]
    }
   ],
   "source": [
    "x_0= np.array([-0.2, 1.2])\n",
    "x_star, fval, it, grad_norm = newton_method(fct_2, grad_fct_2, hessian_fct_2, x_0, max_iter=100)\n",
    "print(f'minimum {fval:<4} at x = {x_star} after {it:<4} iterations with remaining gradient norm {grad_norm}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886cf624-267f-4fa3-9269-0dcb5695ddff",
   "metadata": {},
   "source": [
    "<h4>using approximated gradient and hessian:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "id": "836d7378-417d-4d27-a1fd-d43d071c0e3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T22:35:15.998944Z",
     "iopub.status.busy": "2023-06-05T22:35:15.998444Z",
     "iopub.status.idle": "2023-06-05T22:35:16.012955Z",
     "shell.execute_reply": "2023-06-05T22:35:16.012456Z",
     "shell.execute_reply.started": "2023-06-05T22:35:15.998444Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum 0E-15 at x = [-9.6773873e-14  1.0000000e+00] after 6    iterations with remaining gradient norm 1.4024368078455443e-11\n"
     ]
    }
   ],
   "source": [
    "x_star, fval, it, grad_norm = newton_method(fct_2_dec, grad_estimate_np, hessian_estimate, x_0, max_iter=100, estimate=True)\n",
    "print(f'minimum {fval:<4} at x = {x_star} after {it:<4} iterations with remaining gradient norm {grad_norm}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0874e62-2a40-4bb9-a4b4-b52fad2046a0",
   "metadata": {},
   "source": [
    "<h3>Problem 2.2:</h3>\n",
    "$$f(x_1, x_2)=150(x_1 x_2)^2+(0.5x_1 + 2x_2 - 2)^2$$\n",
    "$$f'(x_1, x_2)=\\begin{pmatrix}\n",
    "300x_2^2 x_1 + 0.5 x_1 + 2x_2 - 2\\\\ \n",
    "300x_1^2 x_2 + 2x_1 + 8x_2 - 8\\\\ \n",
    "\\end{pmatrix}$$\n",
    "$$f''(x_1, x_2)=\\begin{pmatrix}\n",
    "300x_2^2 +0.5 & 600x_1 x_2+2\\\\ \n",
    "600x_1 x_2+2 & 300x_1^2 +8\\\\ \n",
    "\\end{pmatrix}$$\n",
    "\n",
    "on the starting points $x_0$:\n",
    "$$(3.8, 0.1)$$\n",
    "is close to the soltion $x^*=(4,0)$:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcca1ef-00b8-4d95-b3ea-800a0e5eb901",
   "metadata": {},
   "source": [
    "<h4>using exact gradient and hessian:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "id": "0c059de9-015f-43cc-8f9e-af8a9b3ce26b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T22:35:32.925661Z",
     "iopub.status.busy": "2023-06-05T22:35:32.925160Z",
     "iopub.status.idle": "2023-06-05T22:35:32.935669Z",
     "shell.execute_reply": "2023-06-05T22:35:32.935170Z",
     "shell.execute_reply.started": "2023-06-05T22:35:32.925661Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum 0.0  at x = [ 4.00000000e+00 -4.81302457e-17] after 6    iterations with remaining gradient norm 2.238280106885106e-13\n"
     ]
    }
   ],
   "source": [
    "x_0= np.array([3.8, 0.1])\n",
    "x_star, fval, it, grad_norm = newton_method(fct_2, grad_fct_2, hessian_fct_2, x_0, max_iter=100)\n",
    "print(f'minimum {fval:<4} at x = {x_star} after {it:<4} iterations with remaining gradient norm {grad_norm}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0633373-55b1-4645-8463-ec1ec7d26710",
   "metadata": {},
   "source": [
    "<h4>using approximated gradient and hessian:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "id": "cfdec281-1c7d-4bda-a90a-561937f663cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T22:35:41.189621Z",
     "iopub.status.busy": "2023-06-05T22:35:41.189621Z",
     "iopub.status.idle": "2023-06-05T22:35:41.205635Z",
     "shell.execute_reply": "2023-06-05T22:35:41.205635Z",
     "shell.execute_reply.started": "2023-06-05T22:35:41.189621Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum 0E-15 at x = [ 4.00000000e+00 -5.00971536e-14] after 6    iterations with remaining gradient norm 2.2443707358633958e-13\n"
     ]
    }
   ],
   "source": [
    "x_star, fval, it, grad_norm = newton_method(fct_2_dec, grad_estimate_np, hessian_estimate, x_0, max_iter=100, estimate=True)\n",
    "print(f'minimum {fval:<4} at x = {x_star} after {it:<4} iterations with remaining gradient norm {grad_norm}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35671c7f-84ed-4f1d-b2af-0f843e165f0a",
   "metadata": {},
   "source": [
    "<h3>Problem 2.3:</h3>\n",
    "$$f(x_1, x_2)=150(x_1 x_2)^2+(0.5x_1 + 2x_2 - 2)^2$$\n",
    "$$f'(x_1, x_2)=\\begin{pmatrix}\n",
    "300x_2^2 x_1 + 0.5 x_1 + 2x_2 - 2\\\\ \n",
    "300x_1^2 x_2 + 2x_1 + 8x_2 - 8\\\\ \n",
    "\\end{pmatrix}$$\n",
    "$$f''(x_1, x_2)=\\begin{pmatrix}\n",
    "300x_2^2 +0.5 & 600x_1 x_2+2\\\\ \n",
    "600x_1 x_2+2 & 300x_1^2 +8\\\\ \n",
    "\\end{pmatrix}$$\n",
    "\n",
    "on the starting points $x_0$:\n",
    "$$(1.9, 0.6)$$\n",
    "close $x^*=(0,1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b47f0fb-da8a-46f3-9273-3b7bc958b1ba",
   "metadata": {},
   "source": [
    "<h4>using exact gradient and hessian:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "id": "79442ff4-cf51-4b7c-bc76-164262a21052",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T22:35:49.648289Z",
     "iopub.status.busy": "2023-06-05T22:35:49.647789Z",
     "iopub.status.idle": "2023-06-05T22:35:49.663302Z",
     "shell.execute_reply": "2023-06-05T22:35:49.662802Z",
     "shell.execute_reply.started": "2023-06-05T22:35:49.648289Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum 0.0  at x = [4.00000000e+00 1.78205544e-16] after 10   iterations with remaining gradient norm 5.571733890674607e-06\n"
     ]
    }
   ],
   "source": [
    "x_0= np.array([2.0, 0.6])\n",
    "x_star, fval, it, grad_norm = newton_method(fct_2, grad_fct_2, hessian_fct_2, x_0, max_iter=10)\n",
    "print(f'minimum {fval:<4} at x = {x_star} after {it:<4} iterations with remaining gradient norm {grad_norm}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7abf05-02d1-4124-98b8-a627b0f64fbc",
   "metadata": {},
   "source": [
    "<h4>using approximated gradient and hessian:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "id": "3a4b7e76-ed2a-404a-b0d4-e267fcbb85ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T22:35:54.348683Z",
     "iopub.status.busy": "2023-06-05T22:35:54.348182Z",
     "iopub.status.idle": "2023-06-05T22:35:54.355189Z",
     "shell.execute_reply": "2023-06-05T22:35:54.355189Z",
     "shell.execute_reply.started": "2023-06-05T22:35:54.348683Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum 0E-15 at x = [ 4.00000000e+00 -4.98938254e-14] after 10   iterations with remaining gradient norm 8.641134184816249e-13\n"
     ]
    }
   ],
   "source": [
    "x_star, fval, it, grad_norm = newton_method(fct_2_dec, grad_estimate_np, hessian_estimate, x_0, max_iter=100, estimate=True)\n",
    "print(f'minimum {fval:<4} at x = {x_star} after {it:<4} iterations with remaining gradient norm {grad_norm}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9a2e76-ea8b-4d21-abec-d01ed917ffb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
