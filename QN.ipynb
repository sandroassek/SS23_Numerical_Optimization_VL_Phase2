{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "e28d7c3a-6e8e-406b-8fee-045584cf3145",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-11T09:09:49.297861Z",
     "iopub.status.busy": "2023-06-11T09:09:49.297861Z",
     "iopub.status.idle": "2023-06-11T09:09:49.300363Z",
     "shell.execute_reply": "2023-06-11T09:09:49.300363Z",
     "shell.execute_reply.started": "2023-06-11T09:09:49.297861Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import decimal\n",
    "from decimal import Decimal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cd988a-1b9a-450b-b9bb-ca13b1827745",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3>Problem 1:</h3>\n",
    "$$f(x_1, x_2)=100(x_2-x_1^2)^2+(1-x_1)^2$$\n",
    "$$f'(x_1, x_2)=\\begin{pmatrix}\n",
    "-400x_1(x_2-x_1^2)-2(1-x_1)\\\\ \n",
    "200(x_2-x_1^2)\\\\ \n",
    "\\end{pmatrix}$$\n",
    "$$f''(x_1, x_2)=\\begin{pmatrix}\n",
    "1200x_1^2-400x_2+2 & -400x_1\\\\ \n",
    "-400x_1 & 200\\\\ \n",
    "\\end{pmatrix}$$\n",
    "starting points $x_0$:\n",
    "$$(1.2, 1.2), (-1.2, 1), (0.2, 0.8)$$\n",
    "with the minimum at $x^*=(1,1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "5995ae35-06e7-4009-bc46-8719303cdf40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-11T09:09:49.841327Z",
     "iopub.status.busy": "2023-06-11T09:09:49.840827Z",
     "iopub.status.idle": "2023-06-11T09:09:49.859343Z",
     "shell.execute_reply": "2023-06-11T09:09:49.858843Z",
     "shell.execute_reply.started": "2023-06-11T09:09:49.841327Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fct_1(x: np.array) -> int:\n",
    "    return 100*(x[1]-x[0]**2)**2 + (1-x[0])**2\n",
    "\n",
    "def grad_fct_1(x: np.array) -> np.array:\n",
    "    return np.array([-400*x[0]*(x[1]-x[0]**2)-2*(1-x[0]),\n",
    "                    200*(x[1]-x[0]**2)], dtype=np.float64)\n",
    "\n",
    "def hessian_fct_1(x: np.array) -> np.array:\n",
    "    return np.array([[1200*x[0]**2-400*x[1]+2, -400*x[0]], \n",
    "                     [-400*x[0], 200]], dtype=np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e664aa1-f794-475e-9213-04d94dd3b181",
   "metadata": {},
   "source": [
    "<h3>Problem 2:</h3>\n",
    "$$f(x_1, x_2)=150(x_1 x_2)^2+(0.5x_1 + 2x_2 - 2)^2$$\n",
    "$$f'(x_1, x_2)=\\begin{pmatrix}\n",
    "300x_2^2 x_1 + 0.5 x_1 + 2x_2 - 2\\\\ \n",
    "300x_1^2 x_2 + 2x_1 + 8x_2 - 8\\\\ \n",
    "\\end{pmatrix}$$\n",
    "$$f''(x_1, x_2)=\\begin{pmatrix}\n",
    "300x_2^2 +0.5 & 600x_1 x_2+2\\\\ \n",
    "600x_1 x_2+2 & 300x_1^2 +8\\\\ \n",
    "\\end{pmatrix}$$\n",
    "\n",
    "starting points $x_0$:\n",
    "$$(-0.2, 1.2), (3.8, 0.1), (1.9, 0.6)$$<br>\n",
    "with the minimums at $x^*=(0,1)$ and $x^*=(4,0)$ and a saddle point at $(0.43685, 0.10921)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "1e8ad137-7e32-47b0-bf6e-e3ea92d61c99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-11T09:09:49.911388Z",
     "iopub.status.busy": "2023-06-11T09:09:49.910887Z",
     "iopub.status.idle": "2023-06-11T09:09:49.921397Z",
     "shell.execute_reply": "2023-06-11T09:09:49.920896Z",
     "shell.execute_reply.started": "2023-06-11T09:09:49.911388Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fct_2(x: np.array) -> int:\n",
    "    return 150*(x[0] * x[1])**2 + (0.5 * x[0] + 2*x[1] - 2)**2\n",
    "\n",
    "def fct_2_dec(x: np.array) -> int:\n",
    "    return 150*(Decimal(x[0]) * Decimal(x[1]))**2 + (Decimal(0.5) * Decimal(x[0]) + 2*Decimal(x[1]) - 2)**2\n",
    "\n",
    "def grad_fct_2(x: np.array) -> np.array:\n",
    "    return np.array([300*x[0]*x[1]**2 + 0.5*x[0]+2*x[1]-2,\n",
    "                     300*(x[0]**2)*x[1] + 2*x[0]+8*x[1]-8], dtype=np.float64)\n",
    "\n",
    "def hessian_fct_2(x: np.array) -> np.array:\n",
    "    return np.array([[300*x[1]**2 + 0.5, 600*x[0]*x[1] + 2], \n",
    "                     [600*x[0]*x[1] + 2, 300*x[0]**2 + 8]], dtype=np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17ddd88-5d95-4d84-8f42-2ac78083815c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<h2>1. Implementation of BFGS</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "808794c7-78bf-47dc-9e54-1496b4d68965",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-11T09:09:49.966935Z",
     "iopub.status.busy": "2023-06-11T09:09:49.966435Z",
     "iopub.status.idle": "2023-06-11T09:09:49.983450Z",
     "shell.execute_reply": "2023-06-11T09:09:49.982949Z",
     "shell.execute_reply.started": "2023-06-11T09:09:49.966935Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Backtrack(f, x, gradient, pk, alpha_zero=1, rho=0.5, c=0.5):\n",
    "    alpha = alpha_zero\n",
    "    \n",
    "    while not f(x + alpha * pk) <= float(f(x)) + c * alpha * np.dot(gradient, pk):\n",
    "        alpha *= rho\n",
    "        \n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "e2015c88-36ce-4bc5-9151-c789991e0f11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-11T09:09:49.996461Z",
     "iopub.status.busy": "2023-06-11T09:09:49.996461Z",
     "iopub.status.idle": "2023-06-11T09:09:50.014476Z",
     "shell.execute_reply": "2023-06-11T09:09:50.013976Z",
     "shell.execute_reply.started": "2023-06-11T09:09:49.996461Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def BFGS(f, grad, initial_guess, max_iter=1000, tol=1e-6, c=0.5, rho=0.5, estimate=False):\n",
    "    x = initial_guess\n",
    "    num_iter = 0\n",
    "    e_g = Decimal(0.0000000000001)\n",
    "    e_h = Decimal(0.00000001)\n",
    "    \n",
    "    identity = np.eye(len(x))\n",
    "    H = identity\n",
    "\n",
    "    while num_iter < max_iter:\n",
    "        if estimate:\n",
    "            x_dec = np.array([Decimal(val) for val in x])\n",
    "            gradient = grad(f,x_dec,e_g)\n",
    "        else:  \n",
    "            gradient = grad(x)\n",
    "\n",
    "        grad_norm = np.linalg.norm(gradient)\n",
    "        if grad_norm < tol:\n",
    "            break\n",
    "\n",
    "        search_direction = -np.dot(H, gradient)\n",
    "        \n",
    "        alpha = Backtrack(f=f, x=x, gradient=gradient, pk=search_direction, alpha_zero=1, rho=rho, c=c)\n",
    "\n",
    "        x_new = x + alpha * search_direction\n",
    "\n",
    "        if estimate:\n",
    "            x_new_dec = np.array([Decimal(val) for val in x_new])\n",
    "            gradient_new = grad(f,x_new_dec,e_g)\n",
    "            yk = gradient_new - gradient\n",
    "        else:\n",
    "            gradient_new = grad(x_new)\n",
    "            yk = grad(x_new) - gradient\n",
    "\n",
    "        sk = x_new - x\n",
    "        \n",
    "        if (yk.dot(sk))==0:\n",
    "            print('combination of c,rho leads to error')\n",
    "            break\n",
    "\n",
    "        rh = 1.0 / np.dot(yk, sk)\n",
    "        A = identity - rh * np.outer(sk, yk)\n",
    "        H = np.dot(A, np.dot(H, A.T)) + rh * np.outer(sk, sk)\n",
    "\n",
    "        x = x_new\n",
    "        num_iter += 1\n",
    "\n",
    "    return x, f(x), num_iter, grad_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436efced-fc68-42c4-aae6-1a5521cf40a7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<h2>2. Implementation of SR1</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264f0ab1-46ee-42ad-b76e-0c9afe6f8599",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T16:21:10.228117Z",
     "iopub.status.busy": "2023-06-09T16:21:10.227616Z",
     "iopub.status.idle": "2023-06-09T16:21:10.235123Z",
     "shell.execute_reply": "2023-06-09T16:21:10.234622Z",
     "shell.execute_reply.started": "2023-06-09T16:21:10.228117Z"
    }
   },
   "source": [
    "<h3>using line search</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "891469c1-4e70-4ad0-8d42-0b5e76ccaa9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-11T09:09:50.242173Z",
     "iopub.status.busy": "2023-06-11T09:09:50.242173Z",
     "iopub.status.idle": "2023-06-11T09:09:50.262690Z",
     "shell.execute_reply": "2023-06-11T09:09:50.262189Z",
     "shell.execute_reply.started": "2023-06-11T09:09:50.242173Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import line_search\n",
    "\n",
    "def SR1_line(f, grad, initial_guess, max_iter=1000, c=0.5, rho=0.5, tol=1e-6, estimate=False):\n",
    "    x = initial_guess\n",
    "    n = len(x)\n",
    "    e_g = Decimal(0.0000000000001)\n",
    "\n",
    "    Bk = np.eye(n)\n",
    "\n",
    "    for iteration in range(max_iter):\n",
    "\n",
    "        if estimate:\n",
    "            x_dec = np.array([Decimal(val) for val in x])\n",
    "            gradient = grad(f,x_dec,e_g)\n",
    "        else:  \n",
    "            gradient = grad(x)\n",
    "\n",
    "        if np.linalg.norm(gradient) < tol:\n",
    "            break\n",
    "\n",
    "        search_direction = -np.dot(Bk, gradient)\n",
    "\n",
    "        alpha = Backtrack(f=f, x=x, gradient=gradient, pk=search_direction, alpha_zero=1, rho=rho, c=c)\n",
    "\n",
    "        x_new = x + alpha * search_direction\n",
    "\n",
    "        if estimate:\n",
    "            x_new_dec = np.array([Decimal(val) for val in x_new])\n",
    "            gradient_new = grad(f,x_new_dec,e_g)\n",
    "            yk = gradient_new  - gradient\n",
    "        else:\n",
    "            gradient_new = grad(x_new)\n",
    "            yk = gradient_new - gradient\n",
    "        sk = x_new - x\n",
    "\n",
    "        if np.abs(np.dot(sk, yk)) > tol:\n",
    "\n",
    "            Bk += np.outer(sk - np.dot(Bk, yk), sk - np.dot(Bk, yk)) / \\\n",
    "                 np.dot(sk - np.dot(Bk, yk), yk)\n",
    "\n",
    "        x = x_new\n",
    "    \n",
    "    f_star = f(x)\n",
    "    x_star = x\n",
    "    return x_star, f_star, iteration, np.linalg.norm(gradient_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e193b7-cb50-4c98-8983-dd610b492d42",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<h2>3. Gradient and hessian approximation</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "2a61e2d0-5878-4895-b214-3720c8287638",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-11T09:09:50.263690Z",
     "iopub.status.busy": "2023-06-11T09:09:50.263690Z",
     "iopub.status.idle": "2023-06-11T09:09:50.278203Z",
     "shell.execute_reply": "2023-06-11T09:09:50.277702Z",
     "shell.execute_reply.started": "2023-06-11T09:09:50.263690Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use to get gradient as np.array\n",
    "def grad_estimate_np(f, x: np.array, eps: decimal.Decimal):\n",
    "    grad=np.full(len(x), Decimal(0))\n",
    "    for i in range(len(x)):\n",
    "        unit_vector = np.full(len(x), Decimal(0))\n",
    "        unit_vector[i] = Decimal(1)\n",
    "        grad[i] = round(float((f(x + (eps * unit_vector)) - f(x)) / eps), 15)\n",
    "    return np.array(grad, dtype=float)\n",
    "\n",
    "# use for further calculation of hessian estimate\n",
    "def grad_estimate(f, x: np.array, eps: decimal.Decimal):\n",
    "    grad=np.full(len(x), Decimal(0))\n",
    "    for i in range(len(x)):\n",
    "        unit_vector = np.full(len(x), Decimal(0))\n",
    "        unit_vector[i] = Decimal(1)\n",
    "        grad[i] = (f(x + (eps * unit_vector)) - f(x)) / eps\n",
    "    return np.array(grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "3780cd31-06dc-4fbb-ac13-4ae046aa85bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-11T09:09:50.279203Z",
     "iopub.status.busy": "2023-06-11T09:09:50.278703Z",
     "iopub.status.idle": "2023-06-11T09:09:50.293716Z",
     "shell.execute_reply": "2023-06-11T09:09:50.293216Z",
     "shell.execute_reply.started": "2023-06-11T09:09:50.279203Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def hessian_estimate(f, x: np.array, eps_hess: decimal.Decimal, eps_grad):\n",
    "    hessian = np.full((len(x), len(x)), Decimal(0))\n",
    "    for i in range(len(x)):\n",
    "        unit_vector = np.full(len(x), Decimal(0))\n",
    "        unit_vector[i] = Decimal(1)\n",
    "        hessian[:, i] = np.array([round(float(g),15) for g in (np.divide(grad_estimate(f=f, x=(x + (eps_hess * unit_vector)), eps=eps_grad) - grad_estimate(f=f, x=x, eps=eps_grad), eps_hess))])\n",
    "    return np.array(hessian, dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda0d6f5-9e84-4751-ac1c-2d4cce2255e8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<h2>4. Problems to test BFGS</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc577b03-c276-4fd8-80f8-7d0512e4719b",
   "metadata": {},
   "source": [
    "<h3>Problem 1.1:</h3>\n",
    "$$f(x_1, x_2)=100(x_2-x_1^2)^2+(1-x_1)^2$$\n",
    "$$f'(x_1, x_2)=\\begin{pmatrix}\n",
    "-400x_1(x_2-x_1^2)-2(1-x_1)\\\\ \n",
    "200(x_2-x_1^2)\\\\ \n",
    "\\end{pmatrix}$$\n",
    "$$f''(x_1, x_2)=\\begin{pmatrix}\n",
    "1200x_1^2-400x_2+2 & -400x_1\\\\ \n",
    "-400x_1 & 200\\\\ \n",
    "\\end{pmatrix}$$\n",
    "on the starting points $x_0$:\n",
    "$$(1.2, 1.2)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520a308d-4b65-4c00-ae8b-4cc591907740",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T16:05:15.823779Z",
     "iopub.status.busy": "2023-06-09T16:05:15.823779Z",
     "iopub.status.idle": "2023-06-09T16:05:15.830284Z",
     "shell.execute_reply": "2023-06-09T16:05:15.829784Z",
     "shell.execute_reply.started": "2023-06-09T16:05:15.823779Z"
    }
   },
   "source": [
    "<h4>using exact gradient:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "a462fc7b-13dd-4ded-96c0-9e20ee7b74c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-11T09:09:50.776631Z",
     "iopub.status.busy": "2023-06-11T09:09:50.776631Z",
     "iopub.status.idle": "2023-06-11T09:09:50.789642Z",
     "shell.execute_reply": "2023-06-11T09:09:50.789642Z",
     "shell.execute_reply.started": "2023-06-11T09:09:50.776631Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum 5.254864052829333e-17 \n",
      "x = [1.00000001 1.00000001] \n",
      "12 iterations \n",
      "remaining gradient norm 1.551951036325939e-07\n",
      "distance to true solution: 1.4249732950384684e-08\n"
     ]
    }
   ],
   "source": [
    "x_0= np.array([1.2, 1.2])\n",
    "x_true = [1, 1]\n",
    "x_star, fval, it, grad_norm = BFGS(fct_1, grad_fct_1, x_0, c=0.51, rho=0.99, max_iter=1000)\n",
    "print(f'minimum {fval:<4} \\nx = {x_star} \\n{it} iterations \\nremaining gradient norm {grad_norm}')\n",
    "print('distance to true solution:',np.linalg.norm(x_true - x_star))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62e97a3-9aea-43e3-a8e5-28e8a7636374",
   "metadata": {},
   "source": [
    "<h4>using approximated gradient:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "e5a2c3d2-e0cc-4aca-bc13-27ea4b368c86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-11T09:09:51.481236Z",
     "iopub.status.busy": "2023-06-11T09:09:51.481236Z",
     "iopub.status.idle": "2023-06-11T09:09:51.503756Z",
     "shell.execute_reply": "2023-06-11T09:09:51.503255Z",
     "shell.execute_reply.started": "2023-06-11T09:09:51.481236Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum 1.1597360898233273e-16 \n",
      "x = [1.00000001 1.00000002] \n",
      "12 iterations \n",
      "remaining gradient norm 2.3080410061693277e-07\n",
      "distance to true solution: 2.116338497564563e-08\n"
     ]
    }
   ],
   "source": [
    "x_star, fval, it, grad_norm = BFGS(fct_1, grad_estimate_np, x_0, c=0.51, rho=0.99, max_iter=1000, estimate=True)\n",
    "print(f'minimum {fval:<4} \\nx = {x_star} \\n{it} iterations \\nremaining gradient norm {grad_norm}')\n",
    "print('distance to true solution:',np.linalg.norm(x_true - x_star))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1bd538-f699-476a-b0ad-dba666c19263",
   "metadata": {},
   "source": [
    "<h3>Problem 1.2:</h3>\n",
    "$$f(x_1, x_2)=100(x_2-x_1^2)^2+(1-x_1)^2$$\n",
    "$$f'(x_1, x_2)=\\begin{pmatrix}\n",
    "-400x_1(x_2-x_1^2)-2(1-x_1)\\\\ \n",
    "200(x_2-x_1^2)\\\\ \n",
    "\\end{pmatrix}$$\n",
    "$$f''(x_1, x_2)=\\begin{pmatrix}\n",
    "1200x_1^2-400x_2+2 & -400x_1\\\\ \n",
    "-400x_1 & 200\\\\ \n",
    "\\end{pmatrix}$$\n",
    "on the starting points $x_0$:\n",
    "$$(-1.2, 1)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464ef1d6-38d6-44f1-b514-055df9556757",
   "metadata": {},
   "source": [
    "<h4>using exact gradient:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "d6bc4bd4-0422-4e1e-8d7b-dda5f775abd2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-11T09:09:51.590331Z",
     "iopub.status.busy": "2023-06-11T09:09:51.589830Z",
     "iopub.status.idle": "2023-06-11T09:09:51.596335Z",
     "shell.execute_reply": "2023-06-11T09:09:51.596335Z",
     "shell.execute_reply.started": "2023-06-11T09:09:51.590331Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum 1.7886157927455308e-20 \n",
      "x = [1. 1.] \n",
      "30 iterations \n",
      "remaining gradient norm 1.6133208902232782e-09\n",
      "distance to true solution: 2.8827528592999823e-10\n"
     ]
    }
   ],
   "source": [
    "x_0= np.array([-1.2, 1])\n",
    "x_star, fval, it, grad_norm = BFGS(fct_1, grad_fct_1, x_0, c=0.5, rho=0.95, max_iter=1000)\n",
    "print(f'minimum {fval:<4} \\nx = {x_star} \\n{it} iterations \\nremaining gradient norm {grad_norm}')\n",
    "print('distance to true solution:',np.linalg.norm(x_true - x_star))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435628b5-cc1c-42a9-9548-0dcafeda388b",
   "metadata": {},
   "source": [
    "<h4>using approximated gradient:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "7644a034-67cf-4324-a5ab-3ae32e8c1214",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-11T09:09:51.646879Z",
     "iopub.status.busy": "2023-06-11T09:09:51.646378Z",
     "iopub.status.idle": "2023-06-11T09:09:51.658389Z",
     "shell.execute_reply": "2023-06-11T09:09:51.658389Z",
     "shell.execute_reply.started": "2023-06-11T09:09:51.646879Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum 2.6475530861201032e-20 \n",
      "x = [1. 1.] \n",
      "30 iterations \n",
      "remaining gradient norm 1.6121252949085563e-09\n",
      "distance to true solution: 3.5549669645521607e-10\n"
     ]
    }
   ],
   "source": [
    "x_star, fval, it, grad_norm = BFGS(fct_1, grad_estimate_np, x_0, c=0.5, rho=0.95, max_iter=1000, estimate=True)\n",
    "print(f'minimum {fval:<4} \\nx = {x_star} \\n{it} iterations \\nremaining gradient norm {grad_norm}')\n",
    "print('distance to true solution:',np.linalg.norm(x_true - x_star))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9ded9c-995f-4ed9-9918-5f1e70b56b50",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3>Problem 1.3:</h3>\n",
    "$$f(x_1, x_2)=100(x_2-x_1^2)^2+(1-x_1)^2$$\n",
    "$$f'(x_1, x_2)=\\begin{pmatrix}\n",
    "-400x_1(x_2-x_1^2)-2(1-x_1)\\\\ \n",
    "200(x_2-x_1^2)\\\\ \n",
    "\\end{pmatrix}$$\n",
    "$$f''(x_1, x_2)=\\begin{pmatrix}\n",
    "1200x_1^2-400x_2+2 & -400x_1\\\\ \n",
    "-400x_1 & 200\\\\ \n",
    "\\end{pmatrix}$$\n",
    "on the starting points $x_0$:\n",
    "$$(0.2, 0.8)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f97a351-aeb6-479b-8e94-1914ea645fdc",
   "metadata": {},
   "source": [
    "<h4>using exact gradient:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "a0366321-f504-442a-a207-2e248cc2d892",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-11T09:09:51.765981Z",
     "iopub.status.busy": "2023-06-11T09:09:51.765481Z",
     "iopub.status.idle": "2023-06-11T09:09:51.782495Z",
     "shell.execute_reply": "2023-06-11T09:09:51.782495Z",
     "shell.execute_reply.started": "2023-06-11T09:09:51.765981Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum 2.7492625029467825e-18 \n",
      "x = [1. 1.] \n",
      "20 iterations \n",
      "remaining gradient norm 3.2573494428790844e-08\n",
      "distance to true solution: 3.3348498894191675e-09\n"
     ]
    }
   ],
   "source": [
    "x_0= np.array([0.2, 0.8])\n",
    "x_star, fval, it, grad_norm = BFGS(fct_1, grad_fct_1, x_0, c=0.5, rho=0.99, max_iter=1000)\n",
    "print(f'minimum {fval:<4} \\nx = {x_star} \\n{it} iterations \\nremaining gradient norm {grad_norm}')\n",
    "print('distance to true solution:',np.linalg.norm(x_true - x_star))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac36e2a-4908-4578-9333-c218bd839686",
   "metadata": {},
   "source": [
    "<h4>using approximated gradient:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "5bcb0d91-4d13-43eb-aeba-e782ebf13c3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-11T09:09:51.803513Z",
     "iopub.status.busy": "2023-06-11T09:09:51.803513Z",
     "iopub.status.idle": "2023-06-11T09:09:51.829536Z",
     "shell.execute_reply": "2023-06-11T09:09:51.829035Z",
     "shell.execute_reply.started": "2023-06-11T09:09:51.803513Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum 7.58418492950192e-21 \n",
      "x = [1. 1.] \n",
      "20 iterations \n",
      "remaining gradient norm 3.1828489299054078e-09\n",
      "distance to true solution: 1.102901332926877e-10\n"
     ]
    }
   ],
   "source": [
    "x_star, fval, it, grad_norm = BFGS(fct_1, grad_estimate_np, x_0, c=0.5, rho=0.99, max_iter=1000, estimate=True)\n",
    "print(f'minimum {fval:<4} \\nx = {x_star} \\n{it} iterations \\nremaining gradient norm {grad_norm}')\n",
    "print('distance to true solution:',np.linalg.norm(x_true - x_star))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d80c2e5-ac6d-4805-8a1b-f852e9e4be48",
   "metadata": {},
   "source": [
    "<h3>Problem 2.1:</h3>\n",
    "$$f(x_1, x_2)=150(x_1 x_2)^2+(0.5x_1 + 2x_2 - 2)^2$$\n",
    "$$f'(x_1, x_2)=\\begin{pmatrix}\n",
    "300x_2^2 x_1 + 0.5 x_1 + 2x_2 - 2\\\\ \n",
    "300x_1^2 x_2 + 2x_1 + 8x_2 - 8\\\\ \n",
    "\\end{pmatrix}$$\n",
    "$$f''(x_1, x_2)=\\begin{pmatrix}\n",
    "300x_2^2 +0.5 & 600x_1 x_2+2\\\\ \n",
    "600x_1 x_2+2 & 300x_1^2 +8\\\\ \n",
    "\\end{pmatrix}$$\n",
    "\n",
    "on the starting points $x_0$:\n",
    "$$(-0.2, 1.2)$$\n",
    "is close to the soltion $x^*=(0,1)$:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57aa4e28-31d4-4ce1-b568-3438a0e122f2",
   "metadata": {},
   "source": [
    "<h4>using exact gradient:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "3473382d-5a9a-4e75-831b-f177c7ea6f3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-11T09:09:51.899596Z",
     "iopub.status.busy": "2023-06-11T09:09:51.899596Z",
     "iopub.status.idle": "2023-06-11T09:09:51.922616Z",
     "shell.execute_reply": "2023-06-11T09:09:51.922115Z",
     "shell.execute_reply.started": "2023-06-11T09:09:51.899596Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum 2.0926138567587262e-18 \n",
      "x = [-8.22191363e-11  1.00000000e+00] \n",
      "9 iterations \n",
      "remaining gradient norm 2.398960860063864e-08\n",
      "distance to true solution: 5.460623059450867e-10\n"
     ]
    }
   ],
   "source": [
    "x_0= np.array([-0.2, 1.2])\n",
    "x_true_0 = [0,1]\n",
    "x_true_1 = [4,0]\n",
    "x_star, fval, it, grad_norm = BFGS(fct_2, grad_fct_2, x_0, c=0.51, rho=0.99, max_iter=1000)\n",
    "print(f'minimum {fval:<4} \\nx = {x_star} \\n{it} iterations \\nremaining gradient norm {grad_norm}')\n",
    "print('distance to true solution:',np.linalg.norm(x_true_0 - x_star))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab032e41-2e3a-4a01-aa53-c5af1a39664d",
   "metadata": {},
   "source": [
    "<h4>using approximated gradient:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "b5db396f-d44d-45cf-b73a-6331e20c5d24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-11T09:09:52.107275Z",
     "iopub.status.busy": "2023-06-11T09:09:52.106774Z",
     "iopub.status.idle": "2023-06-11T09:09:52.139803Z",
     "shell.execute_reply": "2023-06-11T09:09:52.139302Z",
     "shell.execute_reply.started": "2023-06-11T09:09:52.107275Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum 2.093633286543300799614711971E-18 \n",
      "x = [-8.22688848e-11  1.00000000e+00] \n",
      "9 iterations \n",
      "remaining gradient norm 2.3989608103448146e-08\n",
      "distance to true solution: 5.460324819507533e-10\n"
     ]
    }
   ],
   "source": [
    "x_star, fval, it, grad_norm = BFGS(fct_2_dec, grad_estimate_np, x_0, c=0.51, rho=0.99, max_iter=10000, estimate=True)\n",
    "print(f'minimum {fval:<4} \\nx = {x_star} \\n{it} iterations \\nremaining gradient norm {grad_norm}')\n",
    "print('distance to true solution:',np.linalg.norm(x_true_0 - x_star))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcbfe32-5824-4e61-a85b-c9b5c51cae8d",
   "metadata": {},
   "source": [
    "<h3>Problem 2.2:</h3>\n",
    "$$f(x_1, x_2)=150(x_1 x_2)^2+(0.5x_1 + 2x_2 - 2)^2$$\n",
    "$$f'(x_1, x_2)=\\begin{pmatrix}\n",
    "300x_2^2 x_1 + 0.5 x_1 + 2x_2 - 2\\\\ \n",
    "300x_1^2 x_2 + 2x_1 + 8x_2 - 8\\\\ \n",
    "\\end{pmatrix}$$\n",
    "$$f''(x_1, x_2)=\\begin{pmatrix}\n",
    "300x_2^2 +0.5 & 600x_1 x_2+2\\\\ \n",
    "600x_1 x_2+2 & 300x_1^2 +8\\\\ \n",
    "\\end{pmatrix}$$\n",
    "\n",
    "on the starting points $x_0$:\n",
    "$$(3.8, 0.1)$$\n",
    "is close to the soltion $x^*=(4,0)$:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de79d6b-71e9-40a0-911f-34bdb8bf92db",
   "metadata": {},
   "source": [
    "<h4>using exact gradient:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "f64025c0-1196-4497-91a4-d1bdcbd32ac9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-11T09:09:52.967514Z",
     "iopub.status.busy": "2023-06-11T09:09:52.967514Z",
     "iopub.status.idle": "2023-06-11T09:09:52.977021Z",
     "shell.execute_reply": "2023-06-11T09:09:52.977021Z",
     "shell.execute_reply.started": "2023-06-11T09:09:52.967514Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum 4.583218874437106e-15 \n",
      "x = [3.99999986e+00 2.90509620e-11] \n",
      "6 iterations \n",
      "remaining gradient norm 1.4771310771991682e-07\n",
      "distance to true solution: 1.354852341488151e-07\n"
     ]
    }
   ],
   "source": [
    "x_0= np.array([3.8, 0.1])\n",
    "x_star, fval, it, grad_norm = BFGS(fct_2, grad_fct_2, x_0, c=0.5, rho=0.99, max_iter=1000)\n",
    "print(f'minimum {fval:<4} \\nx = {x_star} \\n{it} iterations \\nremaining gradient norm {grad_norm}')\n",
    "print('distance to true solution:',np.linalg.norm(x_true_1 - x_star))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e0e4f6-e5a2-4362-8e4d-0d721e1640bd",
   "metadata": {},
   "source": [
    "<h4>using approximated gradient:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "5536115b-2572-4cc8-86c5-c3e6a2610b55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-11T09:09:53.294796Z",
     "iopub.status.busy": "2023-06-11T09:09:53.294796Z",
     "iopub.status.idle": "2023-06-11T09:09:53.318815Z",
     "shell.execute_reply": "2023-06-11T09:09:53.318315Z",
     "shell.execute_reply.started": "2023-06-11T09:09:53.294796Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum 4.583215299463996185352639926E-15 \n",
      "x = [3.99999986e+00 2.90009009e-11] \n",
      "6 iterations \n",
      "remaining gradient norm 1.4771310308313813e-07\n",
      "distance to true solution: 1.3548508403594068e-07\n"
     ]
    }
   ],
   "source": [
    "x_star, fval, it, grad_norm = BFGS(fct_2_dec, grad_estimate_np, x_0, c=0.5, rho=0.99, max_iter=896, estimate=True)\n",
    "print(f'minimum {fval:<4} \\nx = {x_star} \\n{it} iterations \\nremaining gradient norm {grad_norm}')\n",
    "print('distance to true solution:',np.linalg.norm(x_true_1 - x_star))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c32d3b5-9e61-4fa4-9976-ad9576428933",
   "metadata": {},
   "source": [
    "<h3>Problem 2.3:</h3>\n",
    "$$f(x_1, x_2)=150(x_1 x_2)^2+(0.5x_1 + 2x_2 - 2)^2$$\n",
    "$$f'(x_1, x_2)=\\begin{pmatrix}\n",
    "300x_2^2 x_1 + 0.5 x_1 + 2x_2 - 2\\\\ \n",
    "300x_1^2 x_2 + 2x_1 + 8x_2 - 8\\\\ \n",
    "\\end{pmatrix}$$\n",
    "$$f''(x_1, x_2)=\\begin{pmatrix}\n",
    "300x_2^2 +0.5 & 600x_1 x_2+2\\\\ \n",
    "600x_1 x_2+2 & 300x_1^2 +8\\\\ \n",
    "\\end{pmatrix}$$\n",
    "\n",
    "on the starting points $x_0$:\n",
    "$$(1.9, 0.6)$$\n",
    "close $x^*=(0,1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a462bd-f2a8-4580-8721-e0c91d00c14f",
   "metadata": {},
   "source": [
    "<h4>using exact gradient:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "93dc06da-72b9-4d52-939b-39c13414dbbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-11T09:09:53.923836Z",
     "iopub.status.busy": "2023-06-11T09:09:53.923335Z",
     "iopub.status.idle": "2023-06-11T09:09:53.938849Z",
     "shell.execute_reply": "2023-06-11T09:09:53.938849Z",
     "shell.execute_reply.started": "2023-06-11T09:09:53.923836Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum 7.670302364212236e-18 \n",
      "x = [ 4.00000000e+00 -2.84353418e-11] \n",
      "9 iterations \n",
      "remaining gradient norm 1.4608400056245542e-07\n",
      "distance to true solution: 4.673719094477779e-09\n"
     ]
    }
   ],
   "source": [
    "x_0= np.array([1.9, 0.6])\n",
    "x_star, fval, it, grad_norm = BFGS(fct_2, grad_fct_2, x_0, c=0.5, rho=0.99, max_iter=1000)\n",
    "print(f'minimum {fval:<4} \\nx = {x_star} \\n{it} iterations \\nremaining gradient norm {grad_norm}')\n",
    "print('distance to true solution:',np.linalg.norm(x_true_1 - x_star))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641c8643-1915-4fc8-9a57-a87be7e25228",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h4>using approximated gradient:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "76e5d103-5a42-4b0b-8537-c3291da8fa32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-11T09:09:54.376725Z",
     "iopub.status.busy": "2023-06-11T09:09:54.376224Z",
     "iopub.status.idle": "2023-06-11T09:09:54.404749Z",
     "shell.execute_reply": "2023-06-11T09:09:54.404248Z",
     "shell.execute_reply.started": "2023-06-11T09:09:54.376725Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum 7.677261353896161266960228935E-18 \n",
      "x = [ 4.00000000e+00 -2.84854271e-11] \n",
      "9 iterations \n",
      "remaining gradient norm 1.460841073911588e-07\n",
      "distance to true solution: 4.673567967861984e-09\n"
     ]
    }
   ],
   "source": [
    "x_star, fval, it, grad_norm = BFGS(fct_2_dec, grad_estimate_np, x_0, c=0.5, rho=0.99, max_iter=10000, estimate=True)\n",
    "print(f'minimum {fval:<4} \\nx = {x_star} \\n{it} iterations \\nremaining gradient norm {grad_norm}')\n",
    "print('distance to true solution:',np.linalg.norm(x_true_1 - x_star))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd21e7ec-4c71-464d-a978-b0f10bc446cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T16:35:02.028297Z",
     "iopub.status.busy": "2023-06-09T16:35:02.027796Z",
     "iopub.status.idle": "2023-06-09T16:35:02.047313Z",
     "shell.execute_reply": "2023-06-09T16:35:02.046312Z",
     "shell.execute_reply.started": "2023-06-09T16:35:02.028297Z"
    },
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<h2>5. Problems to test SR1</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e803a3-4d2d-4662-8b3f-728013a1d5e7",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3>Problem 1.1:</h3>\n",
    "$$f(x_1, x_2)=100(x_2-x_1^2)^2+(1-x_1)^2$$\n",
    "$$f'(x_1, x_2)=\\begin{pmatrix}\n",
    "-400x_1(x_2-x_1^2)-2(1-x_1)\\\\ \n",
    "200(x_2-x_1^2)\\\\ \n",
    "\\end{pmatrix}$$\n",
    "$$f''(x_1, x_2)=\\begin{pmatrix}\n",
    "1200x_1^2-400x_2+2 & -400x_1\\\\ \n",
    "-400x_1 & 200\\\\ \n",
    "\\end{pmatrix}$$\n",
    "on the starting points $x_0$:\n",
    "$$(1.2, 1.2)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583945b8-e54e-4bcb-8be3-2658c21f2bcc",
   "metadata": {},
   "source": [
    "<h4>using exact gradient:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "71013d47-35c4-4597-b730-d6bbb76d668f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-11T09:09:55.590267Z",
     "iopub.status.busy": "2023-06-11T09:09:55.590267Z",
     "iopub.status.idle": "2023-06-11T09:09:55.598775Z",
     "shell.execute_reply": "2023-06-11T09:09:55.598775Z",
     "shell.execute_reply.started": "2023-06-11T09:09:55.590267Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum 2.1672212678386607e-18 \n",
      "x = [1. 1.] \n",
      "11 iterations \n",
      "remaining gradient norm 3.9148685859557664e-08\n",
      "distance to true solution: 2.650703594869426e-09\n"
     ]
    }
   ],
   "source": [
    "x_0= np.array([1.2, 1.2])\n",
    "x_true = [1, 1]\n",
    "x_star, fval, it, grad_norm = SR1_line(fct_1, grad_fct_1, x_0, c=0.34, rho=0.77, max_iter=2000)\n",
    "print(f'minimum {fval:<4} \\nx = {x_star} \\n{it} iterations \\nremaining gradient norm {grad_norm}')\n",
    "print('distance to true solution:',np.linalg.norm(x_true - x_star))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c538c39-597c-4c3d-bf63-71db1ad4c859",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h4>using approximated gradient:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "e1d749a4-fd6c-4e06-8636-20174e0ee2f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-11T09:09:55.657325Z",
     "iopub.status.busy": "2023-06-11T09:09:55.656825Z",
     "iopub.status.idle": "2023-06-11T09:09:55.676842Z",
     "shell.execute_reply": "2023-06-11T09:09:55.676341Z",
     "shell.execute_reply.started": "2023-06-11T09:09:55.657325Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum 2.098175001404131e-18 \n",
      "x = [1. 1.] \n",
      "11 iterations \n",
      "remaining gradient norm 3.9148503855478725e-08\n",
      "distance to true solution: 2.583473219952715e-09\n"
     ]
    }
   ],
   "source": [
    "x_star, fval, it, grad_norm = SR1_line(fct_1, grad_estimate_np, x_0, c=0.34, rho=0.77, max_iter=10000, estimate=True)\n",
    "print(f'minimum {fval:<4} \\nx = {x_star} \\n{it} iterations \\nremaining gradient norm {grad_norm}')\n",
    "print('distance to true solution:',np.linalg.norm(x_true - x_star))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01064ae-11b0-4569-a2c8-4e83f0b57c98",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3>Problem 1.2:</h3>\n",
    "$$f(x_1, x_2)=100(x_2-x_1^2)^2+(1-x_1)^2$$\n",
    "$$f'(x_1, x_2)=\\begin{pmatrix}\n",
    "-400x_1(x_2-x_1^2)-2(1-x_1)\\\\ \n",
    "200(x_2-x_1^2)\\\\ \n",
    "\\end{pmatrix}$$\n",
    "$$f''(x_1, x_2)=\\begin{pmatrix}\n",
    "1200x_1^2-400x_2+2 & -400x_1\\\\ \n",
    "-400x_1 & 200\\\\ \n",
    "\\end{pmatrix}$$\n",
    "on the starting points $x_0$:\n",
    "$$(-1.2, 1)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2954546-7790-4377-88d5-db58942185c6",
   "metadata": {},
   "source": [
    "<h4>using exact gradient:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "0b5a8b95-9ef5-4f56-a1aa-4399b1d93ba8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-11T09:09:55.744900Z",
     "iopub.status.busy": "2023-06-11T09:09:55.744400Z",
     "iopub.status.idle": "2023-06-11T09:09:55.753908Z",
     "shell.execute_reply": "2023-06-11T09:09:55.753908Z",
     "shell.execute_reply.started": "2023-06-11T09:09:55.744900Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum 4.442869342414104e-14 \n",
      "x = [0.99999979 0.99999958] \n",
      "38 iterations \n",
      "remaining gradient norm 1.8849505868609327e-07\n",
      "distance to true solution: 4.7169788067320353e-07\n"
     ]
    }
   ],
   "source": [
    "x_0= np.array([-1.2, 1])\n",
    "x_star, fval, it, grad_norm = SR1_line(fct_1, grad_fct_1, x_0, c=0.51, rho=0.95, max_iter=10000)\n",
    "print(f'minimum {fval:<4} \\nx = {x_star} \\n{it} iterations \\nremaining gradient norm {grad_norm}')\n",
    "print('distance to true solution:',np.linalg.norm(x_true - x_star))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda337e5-08c5-4b0b-bfda-95bc9f9d09a9",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h4>using approximated gradient:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "b5a19bc9-602d-4c08-a218-99c5f6616da3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-11T09:09:55.806453Z",
     "iopub.status.busy": "2023-06-11T09:09:55.806453Z",
     "iopub.status.idle": "2023-06-11T09:09:55.831975Z",
     "shell.execute_reply": "2023-06-11T09:09:55.831474Z",
     "shell.execute_reply.started": "2023-06-11T09:09:55.806453Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum 2.646190809511522e-13 \n",
      "x = [1.00000051 1.00000103] \n",
      "37 iterations \n",
      "remaining gradient norm 5.313738863320231e-07\n",
      "distance to true solution: 1.1511021952801512e-06\n"
     ]
    }
   ],
   "source": [
    "x_star, fval, it, grad_norm = SR1_line(fct_1, grad_estimate_np, x_0, c=0.51, rho=0.95, max_iter=10000, estimate=True)\n",
    "print(f'minimum {fval:<4} \\nx = {x_star} \\n{it} iterations \\nremaining gradient norm {grad_norm}')\n",
    "print('distance to true solution:',np.linalg.norm(x_true - x_star))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d773d95-61bc-400c-a421-73ff888cfb0a",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3>Problem 1.3:</h3>\n",
    "$$f(x_1, x_2)=100(x_2-x_1^2)^2+(1-x_1)^2$$\n",
    "$$f'(x_1, x_2)=\\begin{pmatrix}\n",
    "-400x_1(x_2-x_1^2)-2(1-x_1)\\\\ \n",
    "200(x_2-x_1^2)\\\\ \n",
    "\\end{pmatrix}$$\n",
    "$$f''(x_1, x_2)=\\begin{pmatrix}\n",
    "1200x_1^2-400x_2+2 & -400x_1\\\\ \n",
    "-400x_1 & 200\\\\ \n",
    "\\end{pmatrix}$$\n",
    "on the starting points $x_0$:\n",
    "$$(0.2, 0.8)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e94c7f5-cebd-4662-9095-459f43903b75",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h4>using exact gradient:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "bdf40d0d-bec7-4b39-b4a8-7c5c765565fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-11T09:09:55.916047Z",
     "iopub.status.busy": "2023-06-11T09:09:55.916047Z",
     "iopub.status.idle": "2023-06-11T09:09:55.924555Z",
     "shell.execute_reply": "2023-06-11T09:09:55.924555Z",
     "shell.execute_reply.started": "2023-06-11T09:09:55.916047Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum 8.376977605410461e-17 \n",
      "x = [1. 1.] \n",
      "25 iterations \n",
      "remaining gradient norm 4.0676682963734096e-07\n",
      "distance to true solution: 2.4573247140190953e-09\n"
     ]
    }
   ],
   "source": [
    "x_0= np.array([0.2, 0.8])\n",
    "x_star, fval, it, grad_norm = SR1_line(fct_1, grad_fct_1, x_0, c=0.59, rho=0.95, max_iter=10000)\n",
    "print(f'minimum {fval:<4} \\nx = {x_star} \\n{it} iterations \\nremaining gradient norm {grad_norm}')\n",
    "print('distance to true solution:',np.linalg.norm(x_true - x_star))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7ef276-4c77-4769-a3ca-faf40f84b1de",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h4>using approximated gradient:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "99df61f2-f0b0-4b9b-8887-2626ed04b6d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-11T09:09:55.981103Z",
     "iopub.status.busy": "2023-06-11T09:09:55.980603Z",
     "iopub.status.idle": "2023-06-11T09:09:56.002622Z",
     "shell.execute_reply": "2023-06-11T09:09:56.002121Z",
     "shell.execute_reply.started": "2023-06-11T09:09:55.981103Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum 8.368241720822556e-17 \n",
      "x = [1. 1.] \n",
      "25 iterations \n",
      "remaining gradient norm 4.067416706858997e-07\n",
      "distance to true solution: 2.39080812319887e-09\n"
     ]
    }
   ],
   "source": [
    "x_star, fval, it, grad_norm = SR1_line(fct_1, grad_estimate_np, x_0, c=0.59, rho=0.95, max_iter=10000, estimate=True)\n",
    "print(f'minimum {fval:<4} \\nx = {x_star} \\n{it} iterations \\nremaining gradient norm {grad_norm}')\n",
    "print('distance to true solution:',np.linalg.norm(x_true - x_star))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940b3f83-fc13-49d9-972d-1fae20ea2c91",
   "metadata": {},
   "source": [
    "<h3>Problem 2.1:</h3>\n",
    "$$f(x_1, x_2)=150(x_1 x_2)^2+(0.5x_1 + 2x_2 - 2)^2$$\n",
    "$$f'(x_1, x_2)=\\begin{pmatrix}\n",
    "300x_2^2 x_1 + 0.5 x_1 + 2x_2 - 2\\\\ \n",
    "300x_1^2 x_2 + 2x_1 + 8x_2 - 8\\\\ \n",
    "\\end{pmatrix}$$\n",
    "$$f''(x_1, x_2)=\\begin{pmatrix}\n",
    "300x_2^2 +0.5 & 600x_1 x_2+2\\\\ \n",
    "600x_1 x_2+2 & 300x_1^2 +8\\\\ \n",
    "\\end{pmatrix}$$\n",
    "\n",
    "on the starting points $x_0$:\n",
    "$$(-0.2, 1.2)$$\n",
    "is close to the soltion $x^*=(0,1)$:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ba0760-96cb-4eb8-8765-c449b790590b",
   "metadata": {},
   "source": [
    "<h4>using exact gradient:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "5af65555-5a3a-4cc1-ac4e-63eb73d0f81d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-11T09:09:56.070680Z",
     "iopub.status.busy": "2023-06-11T09:09:56.070180Z",
     "iopub.status.idle": "2023-06-11T09:09:56.079688Z",
     "shell.execute_reply": "2023-06-11T09:09:56.079688Z",
     "shell.execute_reply.started": "2023-06-11T09:09:56.070180Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum 8.912391347522993e-17 \n",
      "x = [6.23112165e-10 1.00000000e+00] \n",
      "9 iterations \n",
      "remaining gradient norm 1.9377023511855158e-07\n",
      "distance to true solution: 2.6958726549807412e-09\n"
     ]
    }
   ],
   "source": [
    "x_0= np.array([-0.2, 1.2])\n",
    "x_true_0 = [0,1]\n",
    "x_true_1 = [4,0]\n",
    "x_star, fval, it, grad_norm = SR1_line(fct_2, grad_fct_2, x_0, c=0.45, rho=0.99, max_iter=10000)\n",
    "print(f'minimum {fval:<4} \\nx = {x_star} \\n{it} iterations \\nremaining gradient norm {grad_norm}')\n",
    "print('distance to true solution:',np.linalg.norm(x_true_0 - x_star))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be8e666-fc3e-47f9-8e27-6eb49d08c97e",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h4>using approximated gradient:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "bb7692e3-91f4-4e60-b563-6916250638fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-11T09:09:56.153251Z",
     "iopub.status.busy": "2023-06-11T09:09:56.152751Z",
     "iopub.status.idle": "2023-06-11T09:09:56.173268Z",
     "shell.execute_reply": "2023-06-11T09:09:56.172767Z",
     "shell.execute_reply.started": "2023-06-11T09:09:56.153251Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum 8.911349853946626006860014086E-17 \n",
      "x = [6.23062418e-10 1.00000000e+00] \n",
      "9 iterations \n",
      "remaining gradient norm 1.9377023536224526e-07\n",
      "distance to true solution: 2.695824431509028e-09\n"
     ]
    }
   ],
   "source": [
    "x_star, fval, it, grad_norm = SR1_line(fct_2_dec, grad_estimate_np, x_0, c=0.45, rho=0.99, max_iter=10000, estimate=True)\n",
    "print(f'minimum {fval:<4} \\nx = {x_star} \\n{it} iterations \\nremaining gradient norm {grad_norm}')\n",
    "print('distance to true solution:',np.linalg.norm(x_true_0 - x_star))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f480d9-6aec-4a38-a32f-65140cc46c54",
   "metadata": {},
   "source": [
    "<h3>Problem 2.2:</h3>\n",
    "$$f(x_1, x_2)=150(x_1 x_2)^2+(0.5x_1 + 2x_2 - 2)^2$$\n",
    "$$f'(x_1, x_2)=\\begin{pmatrix}\n",
    "300x_2^2 x_1 + 0.5 x_1 + 2x_2 - 2\\\\ \n",
    "300x_1^2 x_2 + 2x_1 + 8x_2 - 8\\\\ \n",
    "\\end{pmatrix}$$\n",
    "$$f''(x_1, x_2)=\\begin{pmatrix}\n",
    "300x_2^2 +0.5 & 600x_1 x_2+2\\\\ \n",
    "600x_1 x_2+2 & 300x_1^2 +8\\\\ \n",
    "\\end{pmatrix}$$\n",
    "\n",
    "on the starting points $x_0$:\n",
    "$$(3.8, 0.1)$$\n",
    "is close to the soltion $x^*=(4,0)$:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f6c7eb-e9f7-4a70-80cf-9f4d363b66bd",
   "metadata": {},
   "source": [
    "<h4>using exact gradient:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "c351242f-4fbb-4240-b4ff-aa01966cac9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-11T09:09:57.081548Z",
     "iopub.status.busy": "2023-06-11T09:09:57.081548Z",
     "iopub.status.idle": "2023-06-11T09:09:57.104068Z",
     "shell.execute_reply": "2023-06-11T09:09:57.103568Z",
     "shell.execute_reply.started": "2023-06-11T09:09:57.081548Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum 2.5380414714139796e-13 \n",
      "x = [3.99999899e+00 4.10398969e-10] \n",
      "6 iterations \n",
      "remaining gradient norm 5.052765037900244e-07\n",
      "distance to true solution: 1.0084185597888156e-06\n"
     ]
    }
   ],
   "source": [
    "x_0= np.array([3.8, 0.1])\n",
    "x_star, fval, it, grad_norm = SR1_line(fct_2, grad_fct_2, x_0, c=0.45, rho=0.99, max_iter=1000)\n",
    "print(f'minimum {fval:<4} \\nx = {x_star} \\n{it} iterations \\nremaining gradient norm {grad_norm}')\n",
    "print('distance to true solution:',np.linalg.norm(x_true_1 - x_star))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5ec982-7c52-4258-a6e3-6f4f6479c863",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h4>using approximated gradient:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "d27dadf8-e0fd-4439-a5f5-7ddd47aae0a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-11T09:09:57.543446Z",
     "iopub.status.busy": "2023-06-11T09:09:57.543446Z",
     "iopub.status.idle": "2023-06-11T09:09:57.568967Z",
     "shell.execute_reply": "2023-06-11T09:09:57.568967Z",
     "shell.execute_reply.started": "2023-06-11T09:09:57.543446Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum 2.538040743787989848281280723E-13 \n",
      "x = [3.99999899e+00 4.10348911e-10] \n",
      "6 iterations \n",
      "remaining gradient norm 5.052765032401458e-07\n",
      "distance to true solution: 1.0084184109985716e-06\n"
     ]
    }
   ],
   "source": [
    "x_star, fval, it, grad_norm = SR1_line(fct_2_dec, grad_estimate_np, x_0, c=0.45, rho=0.99, max_iter=1000, estimate=True)\n",
    "print(f'minimum {fval:<4} \\nx = {x_star} \\n{it} iterations \\nremaining gradient norm {grad_norm}')\n",
    "print('distance to true solution:',np.linalg.norm(x_true_1 - x_star))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b03b6cc-9908-445d-a7be-ab8786e6645e",
   "metadata": {},
   "source": [
    "<h3>Problem 2.3:</h3>\n",
    "$$f(x_1, x_2)=150(x_1 x_2)^2+(0.5x_1 + 2x_2 - 2)^2$$\n",
    "$$f'(x_1, x_2)=\\begin{pmatrix}\n",
    "300x_2^2 x_1 + 0.5 x_1 + 2x_2 - 2\\\\ \n",
    "300x_1^2 x_2 + 2x_1 + 8x_2 - 8\\\\ \n",
    "\\end{pmatrix}$$\n",
    "$$f''(x_1, x_2)=\\begin{pmatrix}\n",
    "300x_2^2 +0.5 & 600x_1 x_2+2\\\\ \n",
    "600x_1 x_2+2 & 300x_1^2 +8\\\\ \n",
    "\\end{pmatrix}$$\n",
    "\n",
    "on the starting points $x_0$:\n",
    "$$(1.9, 0.6)$$\n",
    "close $x^*=(0,1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa341368-5c0e-4ed8-bda5-f23e8e2df888",
   "metadata": {},
   "source": [
    "<h4>using exact gradient:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "65c18041-cefc-475f-9947-6bc5c4c6bcbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-11T09:09:58.196006Z",
     "iopub.status.busy": "2023-06-11T09:09:58.196006Z",
     "iopub.status.idle": "2023-06-11T09:09:58.221027Z",
     "shell.execute_reply": "2023-06-11T09:09:58.220528Z",
     "shell.execute_reply.started": "2023-06-11T09:09:58.196006Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum 1.782281402169303e-18 \n",
      "x = [4.00000000e+00 2.25634757e-11] \n",
      "11 iterations \n",
      "remaining gradient norm 1.0531290483455241e-07\n",
      "distance to true solution: 1.5876336082988915e-09\n"
     ]
    }
   ],
   "source": [
    "x_0= np.array([1.9, 0.6])\n",
    "x_star, fval, it, grad_norm = SR1_line(fct_2, grad_fct_2, x_0, c=0.45, rho=0.99, max_iter=100)\n",
    "print(f'minimum {fval:<4} \\nx = {x_star} \\n{it} iterations \\nremaining gradient norm {grad_norm}')\n",
    "print('distance to true solution:',np.linalg.norm(x_true_1 - x_star))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6b95a2-3ac1-4c1a-a2af-18c0f30e692d",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h4>using approximated gradient:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "35e959a1-8aee-4805-a4c9-d9abf4248a3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-11T09:09:59.196366Z",
     "iopub.status.busy": "2023-06-11T09:09:59.196366Z",
     "iopub.status.idle": "2023-06-11T09:09:59.229394Z",
     "shell.execute_reply": "2023-06-11T09:09:59.228894Z",
     "shell.execute_reply.started": "2023-06-11T09:09:59.196366Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum 1.776903008042981077282984878E-18 \n",
      "x = [4.00000000e+00 2.25134128e-11] \n",
      "11 iterations \n",
      "remaining gradient norm 1.0531290275664545e-07\n",
      "distance to true solution: 1.5874828105344866e-09\n"
     ]
    }
   ],
   "source": [
    "x_star, fval, it, grad_norm = SR1_line(fct_2_dec, grad_estimate_np, x_0, c=0.45, rho=0.99, max_iter=10000, estimate=True)\n",
    "print(f'minimum {fval:<4} \\nx = {x_star} \\n{it} iterations \\nremaining gradient norm {grad_norm}')\n",
    "print('distance to true solution:',np.linalg.norm(x_true_1 - x_star))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1f37f7-e5d8-4ead-8404-2aed33990bb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
