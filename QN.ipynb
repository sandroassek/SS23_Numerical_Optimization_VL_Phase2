{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 869,
   "id": "e28d7c3a-6e8e-406b-8fee-045584cf3145",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-10T16:33:57.245309Z",
     "iopub.status.busy": "2023-06-10T16:33:57.244809Z",
     "iopub.status.idle": "2023-06-10T16:33:57.247811Z",
     "shell.execute_reply": "2023-06-10T16:33:57.247811Z",
     "shell.execute_reply.started": "2023-06-10T16:33:57.245309Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import decimal\n",
    "from decimal import Decimal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cd988a-1b9a-450b-b9bb-ca13b1827745",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3>Problem 1:</h3>\n",
    "$$f(x_1, x_2)=100(x_2-x_1^2)^2+(1-x_1)^2$$\n",
    "$$f'(x_1, x_2)=\\begin{pmatrix}\n",
    "-400x_1(x_2-x_1^2)-2(1-x_1)\\\\ \n",
    "200(x_2-x_1^2)\\\\ \n",
    "\\end{pmatrix}$$\n",
    "$$f''(x_1, x_2)=\\begin{pmatrix}\n",
    "1200x_1^2-400x_2+2 & -400x_1\\\\ \n",
    "-400x_1 & 200\\\\ \n",
    "\\end{pmatrix}$$\n",
    "starting points $x_0$:\n",
    "$$(1.2, 1.2), (-1.2, 1), (0.2, 0.8)$$\n",
    "with the minimum at $x^*=(1,1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "id": "5995ae35-06e7-4009-bc46-8719303cdf40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-10T16:33:57.704204Z",
     "iopub.status.busy": "2023-06-10T16:33:57.703703Z",
     "iopub.status.idle": "2023-06-10T16:33:57.708708Z",
     "shell.execute_reply": "2023-06-10T16:33:57.708708Z",
     "shell.execute_reply.started": "2023-06-10T16:33:57.704204Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fct_1(x: np.array) -> int:\n",
    "    return 100*(x[1]-x[0]**2)**2 + (1-x[0])**2\n",
    "\n",
    "def grad_fct_1(x: np.array) -> np.array:\n",
    "    return np.array([-400*x[0]*(x[1]-x[0]**2)-2*(1-x[0]),\n",
    "                    200*(x[1]-x[0]**2)], dtype=np.float64)\n",
    "\n",
    "def hessian_fct_1(x: np.array) -> np.array:\n",
    "    return np.array([[1200*x[0]**2-400*x[1]+2, -400*x[0]], \n",
    "                     [-400*x[0], 200]], dtype=np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e664aa1-f794-475e-9213-04d94dd3b181",
   "metadata": {},
   "source": [
    "<h3>Problem 2:</h3>\n",
    "$$f(x_1, x_2)=150(x_1 x_2)^2+(0.5x_1 + 2x_2 - 2)^2$$\n",
    "$$f'(x_1, x_2)=\\begin{pmatrix}\n",
    "300x_2^2 x_1 + 0.5 x_1 + 2x_2 - 2\\\\ \n",
    "300x_1^2 x_2 + 2x_1 + 8x_2 - 8\\\\ \n",
    "\\end{pmatrix}$$\n",
    "$$f''(x_1, x_2)=\\begin{pmatrix}\n",
    "300x_2^2 +0.5 & 600x_1 x_2+2\\\\ \n",
    "600x_1 x_2+2 & 300x_1^2 +8\\\\ \n",
    "\\end{pmatrix}$$\n",
    "\n",
    "starting points $x_0$:\n",
    "$$(-0.2, 1.2), (3.8, 0.1), (1.9, 0.6)$$<br>\n",
    "with the minimums at $x^*=(0,1)$ and $x^*=(4,0)$ and a saddle point at $(0.43685, 0.10921)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "id": "1e8ad137-7e32-47b0-bf6e-e3ea92d61c99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-10T16:33:57.811296Z",
     "iopub.status.busy": "2023-06-10T16:33:57.810795Z",
     "iopub.status.idle": "2023-06-10T16:33:57.817301Z",
     "shell.execute_reply": "2023-06-10T16:33:57.817301Z",
     "shell.execute_reply.started": "2023-06-10T16:33:57.811296Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fct_2(x: np.array) -> int:\n",
    "    return 150*(x[0] * x[1])**2 + (0.5 * x[0] + 2*x[1] - 2)**2\n",
    "\n",
    "def fct_2_dec(x: np.array) -> int:\n",
    "    return 150*(Decimal(x[0]) * Decimal(x[1]))**2 + (Decimal(0.5) * Decimal(x[0]) + 2*Decimal(x[1]) - 2)**2\n",
    "\n",
    "def grad_fct_2(x: np.array) -> np.array:\n",
    "    return np.array([300*x[0]*x[1]**2 + 0.5*x[0]+2*x[1]-2,\n",
    "                     300*(x[0]**2)*x[1] + 2*x[0]+8*x[1]-8], dtype=np.float64)\n",
    "\n",
    "def hessian_fct_2(x: np.array) -> np.array:\n",
    "    return np.array([[300*x[1]**2 + 0.5, 600*x[0]*x[1] + 2], \n",
    "                     [600*x[0]*x[1] + 2, 300*x[0]**2 + 8]], dtype=np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17ddd88-5d95-4d84-8f42-2ac78083815c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<h2>1. Implementation of BFGS</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "id": "808794c7-78bf-47dc-9e54-1496b4d68965",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-10T16:33:58.299215Z",
     "iopub.status.busy": "2023-06-10T16:33:58.299215Z",
     "iopub.status.idle": "2023-06-10T16:33:58.304219Z",
     "shell.execute_reply": "2023-06-10T16:33:58.303719Z",
     "shell.execute_reply.started": "2023-06-10T16:33:58.299215Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Backtrack(f, x, gradient, pk, alpha_zero=1, rho=0.5, c=0.5):\n",
    "    alpha = alpha_zero\n",
    "    \n",
    "    #print(x, alpha * pk)\n",
    "    #print(float(f(x)) + c * alpha * np.dot(gradient.T, pk))\n",
    "    while not f(x + alpha * pk) <= float(f(x)) + c * alpha * np.dot(gradient, pk):\n",
    "        alpha *= rho\n",
    "        \n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "id": "71396771-cbb2-4a10-a31a-84a25142c9bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-10T16:33:58.307222Z",
     "iopub.status.busy": "2023-06-10T16:33:58.306721Z",
     "iopub.status.idle": "2023-06-10T16:33:58.314729Z",
     "shell.execute_reply": "2023-06-10T16:33:58.314729Z",
     "shell.execute_reply.started": "2023-06-10T16:33:58.307222Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def BFGS(f, grad, x0, max_iter=10000, tol=1e-6, c=0.5, rho=0.5, estimate=False):\n",
    "    x = x0\n",
    "    num_iter = 0\n",
    "    e_g = Decimal(0.0000000000001)\n",
    "    e_h = Decimal(0.00000001)\n",
    "    \n",
    "    identity = np.eye(len(x))\n",
    "    hessian_inv = identity\n",
    "    \n",
    "    while num_iter < max_iter:\n",
    "        if estimate:\n",
    "            x_dec = np.array([Decimal(val) for val in x])\n",
    "            gradient = grad(f,x_dec,e_g)\n",
    "        else:  \n",
    "            gradient = grad(x)\n",
    "        \n",
    "        grad_norm = np.linalg.norm(gradient)\n",
    "        if grad_norm < tol:\n",
    "            break\n",
    "        \n",
    "        search_direction = -np.dot(hessian_inv, gradient)\n",
    "        \n",
    "        alpha = Backtrack(f=f, x=x, gradient=gradient, pk=search_direction, alpha_zero=1, rho=rho, c=c)\n",
    "        \n",
    "        x_new = x + alpha * search_direction\n",
    "        sk = x_new - x\n",
    "        if estimate:\n",
    "            x_new_dec = np.array([Decimal(val) for val in x_new])\n",
    "            yk = grad(f,x_new_dec,e_g) - gradient\n",
    "        else:\n",
    "            yk = grad(x_new) - gradient\n",
    "            \n",
    "        if (yk.dot(sk))==0:\n",
    "            print('combination of c,rho leads to error')\n",
    "            break\n",
    "            \n",
    "        rho_k = 1 / (yk.dot(sk))\n",
    "        hessian_inv = (identity - (rho_k*(sk.dot(yk))))@hessian_inv@(identity - (rho_k*(yk.dot(sk)))) + (rho_k*sk.dot(sk))\n",
    "        x = x_new\n",
    "        num_iter += 1\n",
    "        \n",
    "    x_star = x\n",
    "    f_star = f(x_star)\n",
    "    return x_star, round(float(f_star),15), num_iter, grad_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436efced-fc68-42c4-aae6-1a5521cf40a7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<h2>2. Implementation of SR1</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264f0ab1-46ee-42ad-b76e-0c9afe6f8599",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T16:21:10.228117Z",
     "iopub.status.busy": "2023-06-09T16:21:10.227616Z",
     "iopub.status.idle": "2023-06-09T16:21:10.235123Z",
     "shell.execute_reply": "2023-06-09T16:21:10.234622Z",
     "shell.execute_reply.started": "2023-06-09T16:21:10.228117Z"
    }
   },
   "source": [
    "<h3>using line search</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "id": "891469c1-4e70-4ad0-8d42-0b5e76ccaa9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-10T16:33:59.312086Z",
     "iopub.status.busy": "2023-06-10T16:33:59.311585Z",
     "iopub.status.idle": "2023-06-10T16:33:59.318090Z",
     "shell.execute_reply": "2023-06-10T16:33:59.318090Z",
     "shell.execute_reply.started": "2023-06-10T16:33:59.312086Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import line_search\n",
    "\n",
    "def SR1_line(f, grad, initial_guess, max_iter=1000, c=0.5, rho=0.5, tol=1e-6, estimate=False):\n",
    "    x = initial_guess\n",
    "    n = len(x)\n",
    "    e_g = Decimal(0.0000000000001)\n",
    "\n",
    "    Bk = np.eye(n)\n",
    "\n",
    "    for iteration in range(max_iter):\n",
    "\n",
    "        if estimate:\n",
    "            x_dec = np.array([Decimal(val) for val in x])\n",
    "            gradient = grad(f,x_dec,e_g)\n",
    "        else:  \n",
    "            gradient = grad(x)\n",
    "\n",
    "        if np.linalg.norm(gradient) < tol:\n",
    "            break\n",
    "\n",
    "        search_direction = -np.dot(Bk, gradient)\n",
    "\n",
    "        alpha = Backtrack(f=f, x=x, gradient=gradient, pk=search_direction, alpha_zero=1, rho=rho, c=c)\n",
    "\n",
    "        x_new = x + alpha * search_direction\n",
    "\n",
    "        if estimate:\n",
    "            x_new_dec = np.array([Decimal(val) for val in x_new])\n",
    "            gradient_new = grad(f,x_new_dec,e_g)\n",
    "            yk = gradient_new  - gradient\n",
    "        else:\n",
    "            gradient_new = grad(x_new)\n",
    "            yk = gradient_new - gradient\n",
    "        sk = x_new - x\n",
    "\n",
    "        if np.abs(np.dot(sk, yk)) > tol:\n",
    "\n",
    "            Bk += np.outer(sk - np.dot(Bk, yk), sk - np.dot(Bk, yk)) / \\\n",
    "                 np.dot(sk - np.dot(Bk, yk), yk)\n",
    "\n",
    "        x = x_new\n",
    "    \n",
    "    f_star = f(x)\n",
    "    x_star = x\n",
    "    return x_star, f_star, iteration, np.linalg.norm(gradient_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e193b7-cb50-4c98-8983-dd610b492d42",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<h2>3. Gradient and hessian approximation</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "id": "2a61e2d0-5878-4895-b214-3720c8287638",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-10T16:33:59.332103Z",
     "iopub.status.busy": "2023-06-10T16:33:59.331602Z",
     "iopub.status.idle": "2023-06-10T16:33:59.336606Z",
     "shell.execute_reply": "2023-06-10T16:33:59.336606Z",
     "shell.execute_reply.started": "2023-06-10T16:33:59.332103Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use to get gradient as np.array\n",
    "def grad_estimate_np(f, x: np.array, eps: decimal.Decimal):\n",
    "    grad=np.full(len(x), Decimal(0))\n",
    "    for i in range(len(x)):\n",
    "        unit_vector = np.full(len(x), Decimal(0))\n",
    "        unit_vector[i] = Decimal(1)\n",
    "        grad[i] = round(float((f(x + (eps * unit_vector)) - f(x)) / eps), 15)\n",
    "    return np.array(grad, dtype=float)\n",
    "\n",
    "# use for further calculation of hessian estimate\n",
    "def grad_estimate(f, x: np.array, eps: decimal.Decimal):\n",
    "    grad=np.full(len(x), Decimal(0))\n",
    "    for i in range(len(x)):\n",
    "        unit_vector = np.full(len(x), Decimal(0))\n",
    "        unit_vector[i] = Decimal(1)\n",
    "        grad[i] = (f(x + (eps * unit_vector)) - f(x)) / eps\n",
    "    return np.array(grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "id": "3780cd31-06dc-4fbb-ac13-4ae046aa85bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-10T16:33:59.340109Z",
     "iopub.status.busy": "2023-06-10T16:33:59.339609Z",
     "iopub.status.idle": "2023-06-10T16:33:59.348116Z",
     "shell.execute_reply": "2023-06-10T16:33:59.347616Z",
     "shell.execute_reply.started": "2023-06-10T16:33:59.340109Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def hessian_estimate(f, x: np.array, eps_hess: decimal.Decimal, eps_grad):\n",
    "    hessian = np.full((len(x), len(x)), Decimal(0))\n",
    "    for i in range(len(x)):\n",
    "        unit_vector = np.full(len(x), Decimal(0))\n",
    "        unit_vector[i] = Decimal(1)\n",
    "        hessian[:, i] = np.array([round(float(g),15) for g in (np.divide(grad_estimate(f=f, x=(x + (eps_hess * unit_vector)), eps=eps_grad) - grad_estimate(f=f, x=x, eps=eps_grad), eps_hess))])\n",
    "    return np.array(hessian, dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda0d6f5-9e84-4751-ac1c-2d4cce2255e8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<h2>4. Problems to test BFGS</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc577b03-c276-4fd8-80f8-7d0512e4719b",
   "metadata": {},
   "source": [
    "<h3>Problem 1.1:</h3>\n",
    "$$f(x_1, x_2)=100(x_2-x_1^2)^2+(1-x_1)^2$$\n",
    "$$f'(x_1, x_2)=\\begin{pmatrix}\n",
    "-400x_1(x_2-x_1^2)-2(1-x_1)\\\\ \n",
    "200(x_2-x_1^2)\\\\ \n",
    "\\end{pmatrix}$$\n",
    "$$f''(x_1, x_2)=\\begin{pmatrix}\n",
    "1200x_1^2-400x_2+2 & -400x_1\\\\ \n",
    "-400x_1 & 200\\\\ \n",
    "\\end{pmatrix}$$\n",
    "on the starting points $x_0$:\n",
    "$$(1.2, 1.2)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520a308d-4b65-4c00-ae8b-4cc591907740",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T16:05:15.823779Z",
     "iopub.status.busy": "2023-06-09T16:05:15.823779Z",
     "iopub.status.idle": "2023-06-09T16:05:15.830284Z",
     "shell.execute_reply": "2023-06-09T16:05:15.829784Z",
     "shell.execute_reply.started": "2023-06-09T16:05:15.823779Z"
    }
   },
   "source": [
    "<h4>using exact gradient:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 880,
   "id": "a462fc7b-13dd-4ded-96c0-9e20ee7b74c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-10T16:34:11.746770Z",
     "iopub.status.busy": "2023-06-10T16:34:11.746770Z",
     "iopub.status.idle": "2023-06-10T16:34:12.419348Z",
     "shell.execute_reply": "2023-06-10T16:34:12.419348Z",
     "shell.execute_reply.started": "2023-06-10T16:34:11.746770Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum 2.03e-13 at x = [1.00000045 1.0000009 ] after 195  iterations with remaining gradient norm 5.805101228540534e-07\n",
      "distance to true solution: 1.0088961458002889e-06\n"
     ]
    }
   ],
   "source": [
    "x_0= np.array([1.2, 1.2])\n",
    "x_true = [1, 1]\n",
    "x_star, fval, it, grad_norm = BFGS(fct_1, grad_fct_1, x_0, c=0.51, rho=0.99, max_iter=1000)\n",
    "print(f'minimum {fval:<4} at x = {x_star} after {it:<4} iterations with remaining gradient norm {grad_norm}')\n",
    "print('distance to true solution:',np.linalg.norm(x_true - x_star))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62e97a3-9aea-43e3-a8e5-28e8a7636374",
   "metadata": {},
   "source": [
    "<h4>using approximated gradient:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 881,
   "id": "e5a2c3d2-e0cc-4aca-bc13-27ea4b368c86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-10T16:34:12.420849Z",
     "iopub.status.busy": "2023-06-10T16:34:12.420849Z",
     "iopub.status.idle": "2023-06-10T16:34:14.040741Z",
     "shell.execute_reply": "2023-06-10T16:34:14.040241Z",
     "shell.execute_reply.started": "2023-06-10T16:34:12.420849Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum 2.7e-14 at x = [1.00000016 1.00000033] after 440  iterations with remaining gradient norm 1.477754780616286e-07\n",
      "distance to true solution: 3.6897152000751864e-07\n"
     ]
    }
   ],
   "source": [
    "x_star, fval, it, grad_norm = BFGS(fct_1, grad_estimate_np, x_0, c=0.51, rho=0.99, max_iter=1000, estimate=True)\n",
    "print(f'minimum {fval:<4} at x = {x_star} after {it:<4} iterations with remaining gradient norm {grad_norm}')\n",
    "print('distance to true solution:',np.linalg.norm(x_true - x_star))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1bd538-f699-476a-b0ad-dba666c19263",
   "metadata": {},
   "source": [
    "<h3>Problem 1.2:</h3>\n",
    "$$f(x_1, x_2)=100(x_2-x_1^2)^2+(1-x_1)^2$$\n",
    "$$f'(x_1, x_2)=\\begin{pmatrix}\n",
    "-400x_1(x_2-x_1^2)-2(1-x_1)\\\\ \n",
    "200(x_2-x_1^2)\\\\ \n",
    "\\end{pmatrix}$$\n",
    "$$f''(x_1, x_2)=\\begin{pmatrix}\n",
    "1200x_1^2-400x_2+2 & -400x_1\\\\ \n",
    "-400x_1 & 200\\\\ \n",
    "\\end{pmatrix}$$\n",
    "on the starting points $x_0$:\n",
    "$$(-1.2, 1)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464ef1d6-38d6-44f1-b514-055df9556757",
   "metadata": {},
   "source": [
    "<h4>using exact gradient:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 882,
   "id": "d6bc4bd4-0422-4e1e-8d7b-dda5f775abd2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-10T16:34:14.041742Z",
     "iopub.status.busy": "2023-06-10T16:34:14.041242Z",
     "iopub.status.idle": "2023-06-10T16:34:14.148834Z",
     "shell.execute_reply": "2023-06-10T16:34:14.148834Z",
     "shell.execute_reply.started": "2023-06-10T16:34:14.041742Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum 5.17e-13 at x = [0.99999928 0.99999856] after 161  iterations with remaining gradient norm 6.442759799950901e-07\n",
      "distance to true solution: 1.6095306945376956e-06\n"
     ]
    }
   ],
   "source": [
    "x_0= np.array([-1.2, 1])\n",
    "x_star, fval, it, grad_norm = BFGS(fct_1, grad_fct_1, x_0, c=0.5, rho=0.95, max_iter=1000)\n",
    "print(f'minimum {fval:<4} at x = {x_star} after {it:<4} iterations with remaining gradient norm {grad_norm}')\n",
    "print('distance to true solution:', np.linalg.norm(x_true - x_star))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435628b5-cc1c-42a9-9548-0dcafeda388b",
   "metadata": {},
   "source": [
    "<h4>using approximated gradient:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 883,
   "id": "7644a034-67cf-4324-a5ab-3ae32e8c1214",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-10T16:34:14.150335Z",
     "iopub.status.busy": "2023-06-10T16:34:14.150335Z",
     "iopub.status.idle": "2023-06-10T16:34:14.358514Z",
     "shell.execute_reply": "2023-06-10T16:34:14.358514Z",
     "shell.execute_reply.started": "2023-06-10T16:34:14.150335Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum 0.0  at x = [0.99999999 0.99999997] after 250  iterations with remaining gradient norm 8.884249813094153e-08\n",
      "distance to true solution: 3.150101601598859e-08\n"
     ]
    }
   ],
   "source": [
    "x_star, fval, it, grad_norm = BFGS(fct_1, grad_estimate_np, x_0, c=0.5, rho=0.95, max_iter=1000, estimate=True)\n",
    "print(f'minimum {fval:<4} at x = {x_star} after {it:<4} iterations with remaining gradient norm {grad_norm}')\n",
    "print('distance to true solution:', np.linalg.norm(x_true - x_star))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9ded9c-995f-4ed9-9918-5f1e70b56b50",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3>Problem 1.3:</h3>\n",
    "$$f(x_1, x_2)=100(x_2-x_1^2)^2+(1-x_1)^2$$\n",
    "$$f'(x_1, x_2)=\\begin{pmatrix}\n",
    "-400x_1(x_2-x_1^2)-2(1-x_1)\\\\ \n",
    "200(x_2-x_1^2)\\\\ \n",
    "\\end{pmatrix}$$\n",
    "$$f''(x_1, x_2)=\\begin{pmatrix}\n",
    "1200x_1^2-400x_2+2 & -400x_1\\\\ \n",
    "-400x_1 & 200\\\\ \n",
    "\\end{pmatrix}$$\n",
    "on the starting points $x_0$:\n",
    "$$(0.2, 0.8)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f97a351-aeb6-479b-8e94-1914ea645fdc",
   "metadata": {},
   "source": [
    "<h4>using exact gradient:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "id": "a0366321-f504-442a-a207-2e248cc2d892",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-10T16:34:14.359515Z",
     "iopub.status.busy": "2023-06-10T16:34:14.359515Z",
     "iopub.status.idle": "2023-06-10T16:34:14.734837Z",
     "shell.execute_reply": "2023-06-10T16:34:14.734837Z",
     "shell.execute_reply.started": "2023-06-10T16:34:14.359515Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum 2.91e-13 at x = [0.99999946 0.99999892] after 122  iterations with remaining gradient norm 9.780902008957435e-07\n",
      "distance to true solution: 1.2065051863196908e-06\n"
     ]
    }
   ],
   "source": [
    "x_0= np.array([0.2, 0.8])\n",
    "x_star, fval, it, grad_norm = BFGS(fct_1, grad_fct_1, x_0, c=0.5, rho=0.99, max_iter=1000)\n",
    "print(f'minimum {fval:<4} at x = {x_star} after {it:<4} iterations with remaining gradient norm {grad_norm}')\n",
    "print('distance to true solution:', np.linalg.norm(x_true - x_star))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac36e2a-4908-4578-9333-c218bd839686",
   "metadata": {},
   "source": [
    "<h4>using approximated gradient:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 885,
   "id": "5bcb0d91-4d13-43eb-aeba-e782ebf13c3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-10T16:34:14.736339Z",
     "iopub.status.busy": "2023-06-10T16:34:14.735838Z",
     "iopub.status.idle": "2023-06-10T16:34:15.464464Z",
     "shell.execute_reply": "2023-06-10T16:34:15.464464Z",
     "shell.execute_reply.started": "2023-06-10T16:34:14.736339Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum 1.16e-13 at x = [0.99999966 0.99999932] after 238  iterations with remaining gradient norm 8.134660926768885e-07\n",
      "distance to true solution: 7.623790604592505e-07\n"
     ]
    }
   ],
   "source": [
    "x_star, fval, it, grad_norm = BFGS(fct_1, grad_estimate_np, x_0, c=0.5, rho=0.99, max_iter=1000, estimate=True)\n",
    "print(f'minimum {fval:<4} at x = {x_star} after {it:<4} iterations with remaining gradient norm {grad_norm}')\n",
    "print('distance to true solution:', np.linalg.norm(x_true - x_star))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d80c2e5-ac6d-4805-8a1b-f852e9e4be48",
   "metadata": {},
   "source": [
    "<h3>Problem 2.1:</h3>\n",
    "$$f(x_1, x_2)=150(x_1 x_2)^2+(0.5x_1 + 2x_2 - 2)^2$$\n",
    "$$f'(x_1, x_2)=\\begin{pmatrix}\n",
    "300x_2^2 x_1 + 0.5 x_1 + 2x_2 - 2\\\\ \n",
    "300x_1^2 x_2 + 2x_1 + 8x_2 - 8\\\\ \n",
    "\\end{pmatrix}$$\n",
    "$$f''(x_1, x_2)=\\begin{pmatrix}\n",
    "300x_2^2 +0.5 & 600x_1 x_2+2\\\\ \n",
    "600x_1 x_2+2 & 300x_1^2 +8\\\\ \n",
    "\\end{pmatrix}$$\n",
    "\n",
    "on the starting points $x_0$:\n",
    "$$(-0.2, 1.2)$$\n",
    "is close to the soltion $x^*=(0,1)$:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57aa4e28-31d4-4ce1-b568-3438a0e122f2",
   "metadata": {},
   "source": [
    "<h4>using exact gradient:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "id": "3473382d-5a9a-4e75-831b-f177c7ea6f3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-10T16:34:15.465465Z",
     "iopub.status.busy": "2023-06-10T16:34:15.465465Z",
     "iopub.status.idle": "2023-06-10T16:34:15.571556Z",
     "shell.execute_reply": "2023-06-10T16:34:15.571056Z",
     "shell.execute_reply.started": "2023-06-10T16:34:15.465465Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum 3.4e-14 at x = [-2.70363670e-09  1.00000009e+00] after 40   iterations with remaining gradient norm 9.603133618740993e-07\n",
      "distance to true solution: 9.132737518142627e-08\n"
     ]
    }
   ],
   "source": [
    "x_0= np.array([-0.2, 1.2])\n",
    "x_true_0 = [0,1]\n",
    "x_true_1 = [4,0]\n",
    "x_star, fval, it, grad_norm = BFGS(fct_2, grad_fct_2, x_0, c=0.51, rho=0.99, max_iter=1000)\n",
    "print(f'minimum {fval:<4} at x = {x_star} after {it:<4} iterations with remaining gradient norm {grad_norm}')\n",
    "print('distance to true solution:', np.linalg.norm(x_true_0 - x_star))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab032e41-2e3a-4a01-aa53-c5af1a39664d",
   "metadata": {},
   "source": [
    "<h4>using approximated gradient:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "id": "b5db396f-d44d-45cf-b73a-6331e20c5d24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-10T16:34:15.572558Z",
     "iopub.status.busy": "2023-06-10T16:34:15.572057Z",
     "iopub.status.idle": "2023-06-10T16:34:15.884325Z",
     "shell.execute_reply": "2023-06-10T16:34:15.884325Z",
     "shell.execute_reply.started": "2023-06-10T16:34:15.572558Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum 3.4e-14 at x = [-2.70368646e-09  1.00000009e+00] after 40   iterations with remaining gradient norm 9.603133622675806e-07\n",
      "distance to true solution: 9.13273391451692e-08\n"
     ]
    }
   ],
   "source": [
    "x_star, fval, it, grad_norm = BFGS(fct_2_dec, grad_estimate_np, x_0, c=0.51, rho=0.99, max_iter=10000, estimate=True)\n",
    "print(f'minimum {fval:<4} at x = {x_star} after {it:<4} iterations with remaining gradient norm {grad_norm}')\n",
    "print('distance to true solution:', np.linalg.norm(x_true_0 - x_star)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcbfe32-5824-4e61-a85b-c9b5c51cae8d",
   "metadata": {},
   "source": [
    "<h3>Problem 2.2:</h3>\n",
    "$$f(x_1, x_2)=150(x_1 x_2)^2+(0.5x_1 + 2x_2 - 2)^2$$\n",
    "$$f'(x_1, x_2)=\\begin{pmatrix}\n",
    "300x_2^2 x_1 + 0.5 x_1 + 2x_2 - 2\\\\ \n",
    "300x_1^2 x_2 + 2x_1 + 8x_2 - 8\\\\ \n",
    "\\end{pmatrix}$$\n",
    "$$f''(x_1, x_2)=\\begin{pmatrix}\n",
    "300x_2^2 +0.5 & 600x_1 x_2+2\\\\ \n",
    "600x_1 x_2+2 & 300x_1^2 +8\\\\ \n",
    "\\end{pmatrix}$$\n",
    "\n",
    "on the starting points $x_0$:\n",
    "$$(3.8, 0.1)$$\n",
    "is close to the soltion $x^*=(4,0)$:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de79d6b-71e9-40a0-911f-34bdb8bf92db",
   "metadata": {},
   "source": [
    "<h4>using exact gradient:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 906,
   "id": "f64025c0-1196-4497-91a4-d1bdcbd32ac9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-10T16:51:25.090182Z",
     "iopub.status.busy": "2023-06-10T16:51:25.090182Z",
     "iopub.status.idle": "2023-06-10T16:51:27.899096Z",
     "shell.execute_reply": "2023-06-10T16:51:27.898595Z",
     "shell.execute_reply.started": "2023-06-10T16:51:25.090182Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum 8.66e-13 at x = [3.99999814e+00 7.47299407e-10] after 667  iterations with remaining gradient norm 9.396158766638441e-07\n",
      "distance to true solution: 1.863193068925873e-06\n"
     ]
    }
   ],
   "source": [
    "x_0= np.array([3.8, 0.1])\n",
    "x_star, fval, it, grad_norm = BFGS(fct_2, grad_fct_2, x_0, c=0.5, rho=0.99, max_iter=1000)\n",
    "print(f'minimum {fval:<4} at x = {x_star} after {it:<4} iterations with remaining gradient norm {grad_norm}')\n",
    "print('distance to true solution:', np.linalg.norm(x_true_1 - x_star))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e0e4f6-e5a2-4362-8e4d-0d721e1640bd",
   "metadata": {},
   "source": [
    "<h4>using approximated gradient:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 908,
   "id": "5536115b-2572-4cc8-86c5-c3e6a2610b55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-10T16:51:46.067206Z",
     "iopub.status.busy": "2023-06-10T16:51:46.067206Z",
     "iopub.status.idle": "2023-06-10T16:51:56.775908Z",
     "shell.execute_reply": "2023-06-10T16:51:56.775908Z",
     "shell.execute_reply.started": "2023-06-10T16:51:46.067206Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum 9e-15 at x = [3.99999981e+00 8.09314444e-11] after 895  iterations with remaining gradient norm 9.579027498275813e-08\n",
      "distance to true solution: 1.9147511954389457e-07\n"
     ]
    }
   ],
   "source": [
    "x_star, fval, it, grad_norm = BFGS(fct_2_dec, grad_estimate_np, x_0, c=0.5, rho=0.99, max_iter=896, estimate=True)\n",
    "print(f'minimum {fval:<4} at x = {x_star} after {it:<4} iterations with remaining gradient norm {grad_norm}')\n",
    "print('distance to true solution:', np.linalg.norm(x_true_1 - x_star))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c32d3b5-9e61-4fa4-9976-ad9576428933",
   "metadata": {},
   "source": [
    "<h3>Problem 2.3:</h3>\n",
    "$$f(x_1, x_2)=150(x_1 x_2)^2+(0.5x_1 + 2x_2 - 2)^2$$\n",
    "$$f'(x_1, x_2)=\\begin{pmatrix}\n",
    "300x_2^2 x_1 + 0.5 x_1 + 2x_2 - 2\\\\ \n",
    "300x_1^2 x_2 + 2x_1 + 8x_2 - 8\\\\ \n",
    "\\end{pmatrix}$$\n",
    "$$f''(x_1, x_2)=\\begin{pmatrix}\n",
    "300x_2^2 +0.5 & 600x_1 x_2+2\\\\ \n",
    "600x_1 x_2+2 & 300x_1^2 +8\\\\ \n",
    "\\end{pmatrix}$$\n",
    "\n",
    "on the starting points $x_0$:\n",
    "$$(1.9, 0.6)$$\n",
    "close $x^*=(0,1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a462bd-f2a8-4580-8721-e0c91d00c14f",
   "metadata": {},
   "source": [
    "<h4>using exact gradient:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 909,
   "id": "93dc06da-72b9-4d52-939b-39c13414dbbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-10T16:52:21.472128Z",
     "iopub.status.busy": "2023-06-10T16:52:21.471627Z",
     "iopub.status.idle": "2023-06-10T16:52:22.165224Z",
     "shell.execute_reply": "2023-06-10T16:52:22.165224Z",
     "shell.execute_reply.started": "2023-06-10T16:52:21.472128Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum 1.1e-14 at x = [2.48073771e-09 1.00000005e+00] after 223  iterations with remaining gradient norm 9.341720419513596e-07\n",
      "distance to true solution: 4.943878551800224e-08\n"
     ]
    }
   ],
   "source": [
    "x_0= np.array([1.9, 0.6])\n",
    "x_star, fval, it, grad_norm = BFGS(fct_2, grad_fct_2, x_0, c=0.106, rho=0.99, max_iter=10000)\n",
    "print(f'minimum {fval:<4} at x = {x_star} after {it:<4} iterations with remaining gradient norm {grad_norm}')\n",
    "print('distance to true solution:', np.linalg.norm(x_true_0 - x_star))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641c8643-1915-4fc8-9a57-a87be7e25228",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h4>using approximated gradient:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 910,
   "id": "76e5d103-5a42-4b0b-8537-c3291da8fa32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-10T16:52:22.840305Z",
     "iopub.status.busy": "2023-06-10T16:52:22.839804Z",
     "iopub.status.idle": "2023-06-10T16:52:24.470705Z",
     "shell.execute_reply": "2023-06-10T16:52:24.470705Z",
     "shell.execute_reply.started": "2023-06-10T16:52:22.840305Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum 1.1e-14 at x = [2.48068795e-09 1.00000005e+00] after 223  iterations with remaining gradient norm 9.341720393122907e-07\n",
      "distance to true solution: 4.943874554283383e-08\n"
     ]
    }
   ],
   "source": [
    "x_star, fval, it, grad_norm = BFGS(fct_2_dec, grad_estimate_np, x_0, c=0.106, rho=0.99, max_iter=10000, estimate=True)\n",
    "print(f'minimum {fval:<4} at x = {x_star} after {it:<4} iterations with remaining gradient norm {grad_norm}')\n",
    "print('distance to true solution:', np.linalg.norm(x_true_0 - x_star))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd21e7ec-4c71-464d-a978-b0f10bc446cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T16:35:02.028297Z",
     "iopub.status.busy": "2023-06-09T16:35:02.027796Z",
     "iopub.status.idle": "2023-06-09T16:35:02.047313Z",
     "shell.execute_reply": "2023-06-09T16:35:02.046312Z",
     "shell.execute_reply.started": "2023-06-09T16:35:02.028297Z"
    },
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<h2>5. Problems to test SR1</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e803a3-4d2d-4662-8b3f-728013a1d5e7",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3>Problem 1.1:</h3>\n",
    "$$f(x_1, x_2)=100(x_2-x_1^2)^2+(1-x_1)^2$$\n",
    "$$f'(x_1, x_2)=\\begin{pmatrix}\n",
    "-400x_1(x_2-x_1^2)-2(1-x_1)\\\\ \n",
    "200(x_2-x_1^2)\\\\ \n",
    "\\end{pmatrix}$$\n",
    "$$f''(x_1, x_2)=\\begin{pmatrix}\n",
    "1200x_1^2-400x_2+2 & -400x_1\\\\ \n",
    "-400x_1 & 200\\\\ \n",
    "\\end{pmatrix}$$\n",
    "on the starting points $x_0$:\n",
    "$$(1.2, 1.2)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583945b8-e54e-4bcb-8be3-2658c21f2bcc",
   "metadata": {},
   "source": [
    "<h4>using exact gradient:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 892,
   "id": "71013d47-35c4-4597-b730-d6bbb76d668f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-10T16:34:32.171320Z",
     "iopub.status.busy": "2023-06-10T16:34:32.170819Z",
     "iopub.status.idle": "2023-06-10T16:34:32.175323Z",
     "shell.execute_reply": "2023-06-10T16:34:32.175323Z",
     "shell.execute_reply.started": "2023-06-10T16:34:32.170819Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum 2.1672212678386607e-18 at x = [1. 1.] after 11   iterations with remaining gradient norm 3.9148685859557664e-08\n",
      "distance to true solution: 2.650703594869426e-09\n"
     ]
    }
   ],
   "source": [
    "x_0= np.array([1.2, 1.2])\n",
    "x_true = [1, 1]\n",
    "x_star, fval, it, grad_norm = SR1_line(fct_1, grad_fct_1, x_0, c=0.34, rho=0.77, max_iter=2000)\n",
    "print(f'minimum {fval:<4} at x = {x_star} after {it:<4} iterations with remaining gradient norm {grad_norm}')\n",
    "print('distance to true solution:',np.linalg.norm(x_true - x_star))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c538c39-597c-4c3d-bf63-71db1ad4c859",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h4>using approximated gradient:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 893,
   "id": "e1d749a4-fd6c-4e06-8636-20174e0ee2f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-10T16:34:32.176324Z",
     "iopub.status.busy": "2023-06-10T16:34:32.175823Z",
     "iopub.status.idle": "2023-06-10T16:34:32.186834Z",
     "shell.execute_reply": "2023-06-10T16:34:32.186834Z",
     "shell.execute_reply.started": "2023-06-10T16:34:32.176324Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum 2.098175001404131e-18 at x = [1. 1.] after 11   iterations with remaining gradient norm 3.9148503855478725e-08\n",
      "distance to true solution: 2.583473219952715e-09\n"
     ]
    }
   ],
   "source": [
    "x_star, fval, it, grad_norm = SR1_line(fct_1, grad_estimate_np, x_0, c=0.34, rho=0.77, max_iter=10000, estimate=True)\n",
    "print(f'minimum {fval:<4} at x = {x_star} after {it:<4} iterations with remaining gradient norm {grad_norm}')\n",
    "print('distance to true solution:',np.linalg.norm(x_true - x_star))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01064ae-11b0-4569-a2c8-4e83f0b57c98",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3>Problem 1.2:</h3>\n",
    "$$f(x_1, x_2)=100(x_2-x_1^2)^2+(1-x_1)^2$$\n",
    "$$f'(x_1, x_2)=\\begin{pmatrix}\n",
    "-400x_1(x_2-x_1^2)-2(1-x_1)\\\\ \n",
    "200(x_2-x_1^2)\\\\ \n",
    "\\end{pmatrix}$$\n",
    "$$f''(x_1, x_2)=\\begin{pmatrix}\n",
    "1200x_1^2-400x_2+2 & -400x_1\\\\ \n",
    "-400x_1 & 200\\\\ \n",
    "\\end{pmatrix}$$\n",
    "on the starting points $x_0$:\n",
    "$$(-1.2, 1)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2954546-7790-4377-88d5-db58942185c6",
   "metadata": {},
   "source": [
    "<h4>using exact gradient:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 894,
   "id": "0b5a8b95-9ef5-4f56-a1aa-4399b1d93ba8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-10T16:34:32.187835Z",
     "iopub.status.busy": "2023-06-10T16:34:32.187334Z",
     "iopub.status.idle": "2023-06-10T16:34:32.199844Z",
     "shell.execute_reply": "2023-06-10T16:34:32.199844Z",
     "shell.execute_reply.started": "2023-06-10T16:34:32.187835Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum 4.442869342414104e-14 at x = [0.99999979 0.99999958] after 38   iterations with remaining gradient norm 1.8849505868609327e-07\n",
      "distance to true solution: 4.7169788067320353e-07\n"
     ]
    }
   ],
   "source": [
    "x_0= np.array([-1.2, 1])\n",
    "x_star, fval, it, grad_norm = SR1_line(fct_1, grad_fct_1, x_0, c=0.51, rho=0.95, max_iter=10000)\n",
    "print(f'minimum {fval:<4} at x = {x_star} after {it:<4} iterations with remaining gradient norm {grad_norm}')\n",
    "print('distance to true solution:', np.linalg.norm(x_true - x_star))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda337e5-08c5-4b0b-bfda-95bc9f9d09a9",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h4>using approximated gradient:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "id": "b5a19bc9-602d-4c08-a218-99c5f6616da3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-10T16:34:32.200845Z",
     "iopub.status.busy": "2023-06-10T16:34:32.200845Z",
     "iopub.status.idle": "2023-06-10T16:34:32.215858Z",
     "shell.execute_reply": "2023-06-10T16:34:32.215358Z",
     "shell.execute_reply.started": "2023-06-10T16:34:32.200845Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum 2.646190809511522e-13 at x = [1.00000051 1.00000103] after 37   iterations with remaining gradient norm 5.313738863320231e-07\n",
      "distance to true solution: 1.1511021952801512e-06\n"
     ]
    }
   ],
   "source": [
    "x_star, fval, it, grad_norm = SR1_line(fct_1, grad_estimate_np, x_0, c=0.51, rho=0.95, max_iter=10000, estimate=True)\n",
    "print(f'minimum {fval:<4} at x = {x_star} after {it:<4} iterations with remaining gradient norm {grad_norm}')\n",
    "print('distance to true solution:', np.linalg.norm(x_true - x_star))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d773d95-61bc-400c-a421-73ff888cfb0a",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3>Problem 1.3:</h3>\n",
    "$$f(x_1, x_2)=100(x_2-x_1^2)^2+(1-x_1)^2$$\n",
    "$$f'(x_1, x_2)=\\begin{pmatrix}\n",
    "-400x_1(x_2-x_1^2)-2(1-x_1)\\\\ \n",
    "200(x_2-x_1^2)\\\\ \n",
    "\\end{pmatrix}$$\n",
    "$$f''(x_1, x_2)=\\begin{pmatrix}\n",
    "1200x_1^2-400x_2+2 & -400x_1\\\\ \n",
    "-400x_1 & 200\\\\ \n",
    "\\end{pmatrix}$$\n",
    "on the starting points $x_0$:\n",
    "$$(0.2, 0.8)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e94c7f5-cebd-4662-9095-459f43903b75",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h4>using exact gradient:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 896,
   "id": "bdf40d0d-bec7-4b39-b4a8-7c5c765565fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-10T16:34:32.216859Z",
     "iopub.status.busy": "2023-06-10T16:34:32.216359Z",
     "iopub.status.idle": "2023-06-10T16:34:32.222363Z",
     "shell.execute_reply": "2023-06-10T16:34:32.222363Z",
     "shell.execute_reply.started": "2023-06-10T16:34:32.216859Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum 8.376977605410461e-17 at x = [1. 1.] after 25   iterations with remaining gradient norm 4.0676682963734096e-07\n",
      "distance to true solution: 2.4573247140190953e-09\n"
     ]
    }
   ],
   "source": [
    "x_0= np.array([0.2, 0.8])\n",
    "x_star, fval, it, grad_norm = SR1_line(fct_1, grad_fct_1, x_0, c=0.59, rho=0.95, max_iter=10000)\n",
    "print(f'minimum {fval:<4} at x = {x_star} after {it:<4} iterations with remaining gradient norm {grad_norm}')\n",
    "print('distance to true solution:', np.linalg.norm(x_true - x_star))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7ef276-4c77-4769-a3ca-faf40f84b1de",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h4>using approximated gradient:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 897,
   "id": "99df61f2-f0b0-4b9b-8887-2626ed04b6d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-10T16:34:32.223364Z",
     "iopub.status.busy": "2023-06-10T16:34:32.223364Z",
     "iopub.status.idle": "2023-06-10T16:34:32.238378Z",
     "shell.execute_reply": "2023-06-10T16:34:32.237877Z",
     "shell.execute_reply.started": "2023-06-10T16:34:32.223364Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum 8.368241720822556e-17 at x = [1. 1.] after 25   iterations with remaining gradient norm 4.067416706858997e-07\n",
      "distance to true solution: 2.39080812319887e-09\n"
     ]
    }
   ],
   "source": [
    "x_star, fval, it, grad_norm = SR1_line(fct_1, grad_estimate_np, x_0, c=0.59, rho=0.95, max_iter=10000, estimate=True)\n",
    "print(f'minimum {fval:<4} at x = {x_star} after {it:<4} iterations with remaining gradient norm {grad_norm}')\n",
    "print('distance to true solution:', np.linalg.norm(x_true - x_star))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940b3f83-fc13-49d9-972d-1fae20ea2c91",
   "metadata": {},
   "source": [
    "<h3>Problem 2.1:</h3>\n",
    "$$f(x_1, x_2)=150(x_1 x_2)^2+(0.5x_1 + 2x_2 - 2)^2$$\n",
    "$$f'(x_1, x_2)=\\begin{pmatrix}\n",
    "300x_2^2 x_1 + 0.5 x_1 + 2x_2 - 2\\\\ \n",
    "300x_1^2 x_2 + 2x_1 + 8x_2 - 8\\\\ \n",
    "\\end{pmatrix}$$\n",
    "$$f''(x_1, x_2)=\\begin{pmatrix}\n",
    "300x_2^2 +0.5 & 600x_1 x_2+2\\\\ \n",
    "600x_1 x_2+2 & 300x_1^2 +8\\\\ \n",
    "\\end{pmatrix}$$\n",
    "\n",
    "on the starting points $x_0$:\n",
    "$$(-0.2, 1.2)$$\n",
    "is close to the soltion $x^*=(0,1)$:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ba0760-96cb-4eb8-8765-c449b790590b",
   "metadata": {},
   "source": [
    "<h4>using exact gradient:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 898,
   "id": "5af65555-5a3a-4cc1-ac4e-63eb73d0f81d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-10T16:34:32.239378Z",
     "iopub.status.busy": "2023-06-10T16:34:32.238878Z",
     "iopub.status.idle": "2023-06-10T16:34:32.249887Z",
     "shell.execute_reply": "2023-06-10T16:34:32.249887Z",
     "shell.execute_reply.started": "2023-06-10T16:34:32.239378Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum 8.912391347522993e-17 at x = [6.23112165e-10 1.00000000e+00] after 9    iterations with remaining gradient norm 1.9377023511855158e-07\n",
      "distance to true solution: 2.6958726549807412e-09\n"
     ]
    }
   ],
   "source": [
    "x_0= np.array([-0.2, 1.2])\n",
    "x_true_0 = [0,1]\n",
    "x_true_1 = [4,0]\n",
    "x_star, fval, it, grad_norm = SR1_line(fct_2, grad_fct_2, x_0, c=0.45, rho=0.99, max_iter=10000)\n",
    "print(f'minimum {fval:<4} at x = {x_star} after {it:<4} iterations with remaining gradient norm {grad_norm}')\n",
    "print('distance to true solution:', np.linalg.norm(x_true_0 - x_star))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be8e666-fc3e-47f9-8e27-6eb49d08c97e",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h4>using approximated gradient:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "id": "bb7692e3-91f4-4e60-b563-6916250638fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-10T16:34:32.250888Z",
     "iopub.status.busy": "2023-06-10T16:34:32.250888Z",
     "iopub.status.idle": "2023-06-10T16:34:32.272406Z",
     "shell.execute_reply": "2023-06-10T16:34:32.272406Z",
     "shell.execute_reply.started": "2023-06-10T16:34:32.250888Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum 8.911349853946626006860014086E-17 at x = [6.23062418e-10 1.00000000e+00] after 9    iterations with remaining gradient norm 1.9377023536224526e-07\n",
      "distance to true solution: 2.695824431509028e-09\n"
     ]
    }
   ],
   "source": [
    "x_star, fval, it, grad_norm = SR1_line(fct_2_dec, grad_estimate_np, x_0, c=0.45, rho=0.99, max_iter=10000, estimate=True)\n",
    "print(f'minimum {fval:<4} at x = {x_star} after {it:<4} iterations with remaining gradient norm {grad_norm}')\n",
    "print('distance to true solution:', np.linalg.norm(x_true_0 - x_star))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f480d9-6aec-4a38-a32f-65140cc46c54",
   "metadata": {},
   "source": [
    "<h3>Problem 2.2:</h3>\n",
    "$$f(x_1, x_2)=150(x_1 x_2)^2+(0.5x_1 + 2x_2 - 2)^2$$\n",
    "$$f'(x_1, x_2)=\\begin{pmatrix}\n",
    "300x_2^2 x_1 + 0.5 x_1 + 2x_2 - 2\\\\ \n",
    "300x_1^2 x_2 + 2x_1 + 8x_2 - 8\\\\ \n",
    "\\end{pmatrix}$$\n",
    "$$f''(x_1, x_2)=\\begin{pmatrix}\n",
    "300x_2^2 +0.5 & 600x_1 x_2+2\\\\ \n",
    "600x_1 x_2+2 & 300x_1^2 +8\\\\ \n",
    "\\end{pmatrix}$$\n",
    "\n",
    "on the starting points $x_0$:\n",
    "$$(3.8, 0.1)$$\n",
    "is close to the soltion $x^*=(4,0)$:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f6c7eb-e9f7-4a70-80cf-9f4d363b66bd",
   "metadata": {},
   "source": [
    "<h4>using exact gradient:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 900,
   "id": "c351242f-4fbb-4240-b4ff-aa01966cac9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-10T16:34:32.273407Z",
     "iopub.status.busy": "2023-06-10T16:34:32.273407Z",
     "iopub.status.idle": "2023-06-10T16:34:32.284917Z",
     "shell.execute_reply": "2023-06-10T16:34:32.284418Z",
     "shell.execute_reply.started": "2023-06-10T16:34:32.273407Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum 2.5380414714139796e-13 at x = [3.99999899e+00 4.10398969e-10] after 6    iterations with remaining gradient norm 5.052765037900244e-07\n",
      "distance to true solution: 1.0084185597888156e-06\n"
     ]
    }
   ],
   "source": [
    "x_0= np.array([3.8, 0.1])\n",
    "x_star, fval, it, grad_norm = SR1_line(fct_2, grad_fct_2, x_0, c=0.45, rho=0.99, max_iter=1000)\n",
    "print(f'minimum {fval:<4} at x = {x_star} after {it:<4} iterations with remaining gradient norm {grad_norm}')\n",
    "print('distance to true solution:', np.linalg.norm(x_true_1 - x_star))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5ec982-7c52-4258-a6e3-6f4f6479c863",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h4>using approximated gradient:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 901,
   "id": "d27dadf8-e0fd-4439-a5f5-7ddd47aae0a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-10T16:34:32.285418Z",
     "iopub.status.busy": "2023-06-10T16:34:32.285418Z",
     "iopub.status.idle": "2023-06-10T16:34:32.308938Z",
     "shell.execute_reply": "2023-06-10T16:34:32.308938Z",
     "shell.execute_reply.started": "2023-06-10T16:34:32.285418Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum 2.538040743787989848281280723E-13 at x = [3.99999899e+00 4.10348911e-10] after 6    iterations with remaining gradient norm 5.052765032401458e-07\n",
      "distance to true solution: 1.0084184109985716e-06\n"
     ]
    }
   ],
   "source": [
    "x_star, fval, it, grad_norm = SR1_line(fct_2_dec, grad_estimate_np, x_0, c=0.45, rho=0.99, max_iter=1000, estimate=True)\n",
    "print(f'minimum {fval:<4} at x = {x_star} after {it:<4} iterations with remaining gradient norm {grad_norm}')\n",
    "print('distance to true solution:', np.linalg.norm(x_true_1 - x_star))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b03b6cc-9908-445d-a7be-ab8786e6645e",
   "metadata": {},
   "source": [
    "<h3>Problem 2.3:</h3>\n",
    "$$f(x_1, x_2)=150(x_1 x_2)^2+(0.5x_1 + 2x_2 - 2)^2$$\n",
    "$$f'(x_1, x_2)=\\begin{pmatrix}\n",
    "300x_2^2 x_1 + 0.5 x_1 + 2x_2 - 2\\\\ \n",
    "300x_1^2 x_2 + 2x_1 + 8x_2 - 8\\\\ \n",
    "\\end{pmatrix}$$\n",
    "$$f''(x_1, x_2)=\\begin{pmatrix}\n",
    "300x_2^2 +0.5 & 600x_1 x_2+2\\\\ \n",
    "600x_1 x_2+2 & 300x_1^2 +8\\\\ \n",
    "\\end{pmatrix}$$\n",
    "\n",
    "on the starting points $x_0$:\n",
    "$$(1.9, 0.6)$$\n",
    "close $x^*=(0,1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa341368-5c0e-4ed8-bda5-f23e8e2df888",
   "metadata": {},
   "source": [
    "<h4>using exact gradient:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 902,
   "id": "65c18041-cefc-475f-9947-6bc5c4c6bcbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-10T16:34:32.310439Z",
     "iopub.status.busy": "2023-06-10T16:34:32.309939Z",
     "iopub.status.idle": "2023-06-10T16:34:32.325453Z",
     "shell.execute_reply": "2023-06-10T16:34:32.325453Z",
     "shell.execute_reply.started": "2023-06-10T16:34:32.310439Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum 1.782281402169303e-18 at x = [4.00000000e+00 2.25634757e-11] after 11   iterations with remaining gradient norm 1.0531290483455241e-07\n",
      "distance to true solution: 1.5876336082988915e-09\n"
     ]
    }
   ],
   "source": [
    "x_0= np.array([1.9, 0.6])\n",
    "x_star, fval, it, grad_norm = SR1_line(fct_2, grad_fct_2, x_0, c=0.45, rho=0.99, max_iter=100)\n",
    "print(f'minimum {fval:<4} at x = {x_star} after {it:<4} iterations with remaining gradient norm {grad_norm}')\n",
    "print('distance to true solution:', np.linalg.norm(x_true_1 - x_star))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6b95a2-3ac1-4c1a-a2af-18c0f30e692d",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h4>using approximated gradient:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 903,
   "id": "35e959a1-8aee-4805-a4c9-d9abf4248a3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-10T16:34:32.326453Z",
     "iopub.status.busy": "2023-06-10T16:34:32.326453Z",
     "iopub.status.idle": "2023-06-10T16:34:32.357980Z",
     "shell.execute_reply": "2023-06-10T16:34:32.357980Z",
     "shell.execute_reply.started": "2023-06-10T16:34:32.326453Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum 1.776903008042981077282984878E-18 at x = [4.00000000e+00 2.25134128e-11] after 11   iterations with remaining gradient norm 1.0531290275664545e-07\n",
      "distance to true solution: 1.5874828105344866e-09\n"
     ]
    }
   ],
   "source": [
    "x_star, fval, it, grad_norm = SR1_line(fct_2_dec, grad_estimate_np, x_0, c=0.45, rho=0.99, max_iter=10000, estimate=True)\n",
    "print(f'minimum {fval:<4} at x = {x_star} after {it:<4} iterations with remaining gradient norm {grad_norm}')\n",
    "print('distance to true solution:', np.linalg.norm(x_true_1 - x_star))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
